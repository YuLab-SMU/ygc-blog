{"MyPackages/clusterProfiler/KEGG的分类数据更新":{"slug":"MyPackages/clusterProfiler/KEGG的分类数据更新","filePath":"MyPackages/clusterProfiler/KEGG的分类数据更新.md","title":"KEGG的分类数据更新","links":[],"tags":["clusterProfiler","KEGG"],"content":"Dear clusterProfiler maintainers,\nFirst, thank you for developing and maintaining this incredibly useful package! I’ve been using clusterProfiler extensively for enrichment analysis and it’s been invaluable for my research.\nI’m encountering an issue with KEGG enrichment analysis where some pathways show NA values for both category and subcategory fields, even though the pathways themselves are valid and statistically significant.\nDescription\nWhen performing KEGG enrichment analysis using enrichKEGG followed by setReadable, some pathways show NA values for both category and subcategory fields, even though the pathways themselves are valid and significant.\nProblem\nThe pathways mmu04082 (Neuroactive ligand-receptor interaction) and mmu04517 (IgSF CAM signaling) return NA for category and subcategory columns in the results, while other pathways have proper classification information.\nQuestions\nIs this a known issue with specific KEGG pathways?\nIs there a way to automatically retrieve the missing category information?\nShould the category information be populated from a different source or database?\nI’ve verified that these pathways exist in the KEGG database and are valid, but the classification metadata seems to be missing in the enrichment results.\nAny guidance on how to resolve this would be greatly appreciated. Thank you for your time and continued support of this excellent package!\nBest regards,\nSophia\nformula &lt;- compareCluster(ENTREZID~cluster, data=GeneClusterDF,\n                          fun=&#039;enrichKEGG&#039;, \n                          organism = &quot;mmu&quot;,  # 小鼠的KEGG organism code\n                          pvalueCutoff=0.05,\n                          pAdjustMethod = &quot;BH&quot;)\nformula &lt;- setReadable(formula, \n                       OrgDb = &quot;org.Mm.eg.db&quot;, \n                       keyType = &quot;ENTREZID&quot;)\nhead(as.data.frame(formula))\n&gt; head(as.data.frame(formula))\n  Cluster cluster                             category         subcategory       ID                  Description GeneRatio   BgRatio RichFactor FoldEnrichment\n1       0       0                                 &lt;NA&gt;                &lt;NA&gt; mmu04082 Neuroactive ligand signaling    14/113 196/10632 0.07142857       6.720607\n2       0       0                                 &lt;NA&gt;                &lt;NA&gt; mmu04517           IgSF CAM signaling    16/113 300/10632 0.05333333       5.018053\n3       0       0                   Organismal Systems      Nervous system mmu04724        Glutamatergic synapse    10/113 117/10632 0.08547009       8.041752\n4       0       0 Environmental Information Processing Signal transduction mmu04020    Calcium signaling pathway    13/113 255/10632 0.05098039       4.796668\n5       0       0                   Organismal Systems      Nervous system mmu04727            GABAergic synapse     8/113  91/10632 0.08791209       8.271516\n6       0       0 Environmental Information Processing Signal transduction mmu04024       cAMP signaling pathway    11/113 224/10632 0.04910714       4.620417\n    zScore       pvalue     p.adjust       qvalue                                                                                              geneID Count\n1 8.378035 1.822353e-08 4.355424e-06 3.356966e-06          Adcy2/Gabbr2/Gabra2/Gabrb1/Gnao1/Gria2/Grin2c/Grm3/Hrh1/Plcb1/Slc1a2/Slc1a3/Slc6a1/Slc6a11    14\n2 7.316833 1.016818e-07 1.215097e-05 9.365424e-06 Actr3b/Ank2/Cables1/Cadm1/Cadm2/Cntn1/Kcnq3/Kirrel3/Lrrc4c/Mapk10/Ncam1/Nrcam/Nrp1/Srgap1/Tjp1/Vav3    16\n3 7.937944 4.238134e-07 3.376380e-05 2.602363e-05                                        Adcy2/Glul/Gnao1/Gria2/Grin2c/Grm3/Itpr2/Plcb1/Slc1a2/Slc1a3    10\n4 6.360275 2.911406e-06 1.739565e-04 1.340779e-04                     Adcy2/Atp2b2/Camk1d/Camk2g/Fgf1/Fgfr3/Grin2c/Hrh1/Itpr2/Phka1/Phkg1/Plcb1/Vegfa    13\n5 7.220110 5.181671e-06 2.476839e-04 1.909037e-04                                                Adcy2/Gabbr2/Gabra2/Gabrb1/Glul/Gnao1/Slc6a1/Slc6a11     8\n6 5.675943 2.505014e-05 9.978306e-04 7.690833e-04                               Adcy2/Atp1a2/Atp2b2/Camk2g/Gabbr2/Gli3/Gria2/Grin2c/Mapk10/Ptch1/Vav3    11\n&gt; sessionInfo()\nR version 4.5.2 (2025-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 11 x64 (build 22000)\n \nMatrix products: default\n  LAPACK version 3.12.1\n \nlocale:\n[1] LC_COLLATE=Chinese (Simplified)_China.utf8  LC_CTYPE=Chinese (Simplified)_China.utf8    LC_MONETARY=Chinese (Simplified)_China.utf8\n[4] LC_NUMERIC=C                                LC_TIME=Chinese (Simplified)_China.utf8    \n \ntime zone: Asia/Shanghai\ntzcode source: internal\n \nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods   base     \n \nother attached packages:\n [1] dplyr_1.1.4            ReactomePA_1.54.0      GseaVis_0.0.5          pathview_1.50.0        DOSE_4.4.0             enrichplot_1.30.0     \n [7] ggplot2_4.0.1          msigdbr_25.1.1         org.Mm.eg.db_3.22.0    AnnotationDbi_1.72.0   IRanges_2.44.0         S4Vectors_0.48.0      \n[13] Biobase_2.70.0         BiocGenerics_0.56.0    generics_0.1.4         clusterProfiler_4.18.0\n \nloaded via a namespace (and not attached):\n  [1] pheatmap_1.0.13         pak_0.9.0               DBI_1.2.3               httr_1.4.7              BiocParallel_1.44.0     yulab.utils_0.2.1      \n  [7] ggplotify_0.1.3         babelgene_22.9          pillar_1.11.1           Rgraphviz_2.54.0        R6_2.6.1                mime_0.13              \n [13] reticulate_1.44.1       viridis_0.6.5           ROCR_1.0-11             graphite_1.56.0         S7_0.2.1                parallelly_1.45.1      \n [19] GlobalOptions_0.1.2     polyclip_1.10-7         htmltools_0.5.8.1       remotes_2.5.0           ggrepel_0.9.6           fgsea_1.36.0           \n [25] forcats_1.0.1           spatstat.utils_3.2-0    fitdistrplus_1.2-4      tidyselect_1.2.1        utf8_1.2.6              RSQLite_2.4.4          \n [31] cowplot_1.2.0           scattermore_1.2         sessioninfo_1.2.3       spatstat.data_3.1-9     gridExtra_2.3           fs_1.6.6               \n [37] sctransform_0.4.2       RColorBrewer_1.1-3      future.apply_1.20.0     graph_1.88.0            R.oo_1.27.1             RcppHNSW_0.6.0         \n [43] reactome.db_1.94.0      Rtsne_0.17              lazyeval_0.2.2          scales_1.4.0            treeio_1.34.0           R.utils_2.13.0         \n [49] KEGGgraph_1.70.0        bitops_1.0-9            R.methodsS3_1.8.2       KEGGREST_1.50.0         promises_1.5.0          shape_1.4.6.1          \n [55] zoo_1.8-14              RSpectra_0.16-2         assertthat_0.2.1        tools_4.5.2             ape_5.8-1               shiny_1.11.1           \n [61] rlang_1.1.6             ggridges_0.5.7          evaluate_1.0.5          otel_0.2.0              reshape2_1.4.5          devtools_2.4.6         \n [67] colorspace_2.1-2        ellipsis_0.3.2          data.table_1.17.8       withr_3.0.2             tibble_3.3.0            RCurl_1.98-1.17        \n [73] xtable_1.8-4            plyr_1.8.9              aplot_0.2.9             systemfonts_1.3.1       httpuv_1.6.16           MASS_7.3-65            \n [79] stringr_1.6.0           openxlsx_4.2.8.1        GO.db_3.22.0            vctrs_0.6.5             lifecycle_1.0.4         codetools_0.2-20       \n [85] fastDummies_1.7.5       nlme_3.1-168            Seqinfo_1.0.0           future_1.68.0           pkgload_1.4.1           Rcpp_1.1.0             \n [91] rstudioapi_0.17.1       patchwork_1.3.2         stringi_1.8.7           pbapply_1.7-4           cachem_1.1.0            BiocManager_1.30.27    \n [97] tidytree_0.4.6          listenv_0.10.0          XVector_0.50.0          plotly_4.11.0           ggtree_4.0.1            pkgbuild_1.4.8         \n[103] ggfun_0.2.0             ggtangle_0.0.8          htmlwidgets_1.6.4       memoise_2.0.1           crayon_1.5.3            gridGraphics_0.5-1     \n[109] rappdirs_0.3.3          GOSemSim_2.36.0         png_0.1-8               progressr_0.18.0        fastmap_1.2.0           tidygraph_1.3.1        \n[115] tidyr_1.3.1             pkgconfig_2.0.3         cli_3.6.5               ggforce_0.5.0           ggiraph_0.9.2           lmtest_0.9-40          \n[121] usethis_3.2.1           RcppAnnoy_0.0.22        gdtools_0.4.4           viridisLite_0.4.2       splines_4.5.2           blob_1.2.4             \n[127] XML_3.99-0.20           globals_0.18.0          knitr_1.50              ica_1.0-3               spam_2.11-1             dichromat_2.0-0.1      \n[133] compiler_4.5.2          grid_4.5.2              bit_4.6.0               ggpp_0.5.9              glue_1.8.0              sp_2.2-0               \n[139] digest_0.6.38           irlba_2.3.5.1           graphlayouts_1.2.2      fontLiberation_0.1.0    fontBitstreamVera_0.1.1 dotCall64_1.2          \n[145] tweenr_2.0.3            lattice_0.22-7          ggraph_2.2.2            gson_0.1.0              igraph_2.2.1            ggnewscale_0.5.2       \n[151] qvalue_2.42.0           later_1.4.4             parallel_4.5.2          fontquiver_0.2.1        miniUI_0.1.2            gtable_0.3.6           \n[157] xfun_0.54               Biostrings_2.78.0       curl_7.0.0              org.Hs.eg.db_3.22.0     KernSmooth_2.23-26      survival_3.8-3         \n[163] jsonlite_2.0.0          magrittr_2.0.4          purrr_1.2.0             matrixStats_1.5.0       Matrix_1.7-4            SeuratObject_5.2.0     \n[169] fastmatch_1.1-6         RANN_2.6.2              circlize_0.4.16         polynom_1.4-1           bit64_4.6.0-1           cluster_2.1.8.1        \n[175] farver_2.1.2            zip_2.3.3  \n来自用户的灵魂拷问，连着三个问句，这必须是有经历过探索的。我看了一下，这个KEGG category的映射关系是预存在包里的，然后在Bioconductor 3.22新发行版的时候，我忘记去更一下数据了。\n那么KEGG本来就是在线抓取数据，为什么这个要预存数据呢？也在线爬它不香吗？这个我肯定是有原因的。\n\n\n因为这个category，不管你是什么物种，都是这样的分类，所以它是通用的。所有人一样用，这就适合存一份。\n\n\n另一方面，爬这个category的信息，我用的rvest去写的爬虫，我不想放到clusterProfiler的代码里，因为放进去，就会增加依赖包。\n\n\n我给用户的回复：\nThe KEGG pathway information is cached within the package. I apologize for not updating it before the latest release. Thank you for bringing this to my attention; the issue has now been resolved.\n&gt; head(x, 2)\n                                     category                         subcategory       ID                  Description GeneRatio   BgRatio RichFactor FoldEnrichment   zScore       pvalue     p.adjust       qvalue\nmmu04082 Environmental Information Processing Signaling molecules and interaction mmu04082 Neuroactive ligand signaling     30/30 196/10632  0.1530612       54.24490 40.02145 9.349530e-54 1.084545e-51 4.527141e-52\nmmu05032                       Human Diseases                Substance dependence mmu05032           Morphine addiction     13/30  93/10632  0.1397849       49.53978 25.00883 7.801411e-20 4.524818e-18 1.888763e-18\n                                                                                                                                                                                             geneID Count\nmmu04082 216227/11423/14678/14701/11549/14654/18750/57385/11539/15559/14683/11515/11541/104111/18442/242425/14806/13491/21334/63993/13488/213788/57014/108015/14396/21337/53623/110886/11513/210044    30\nmmu05032  \n昨晚给我的留言，早上就许愿成功。\n\n这个锅我是认的。\n\n\n正如前文所的，预存数据是有原因的，但这也带来了要定期更新的问题。因为这才更没多久，又来反映没更了。这样子手工更，就太费叔了，一下子把自己搞手残了。\n所谓那里有压迫，那里就有反抗，不能让它把我们给欺负了。\n我的解决方案就是用github action。写个workflow来干这个事情。\n\n触发条件 ：每周日 UTC 时间 00:00 ( cron: ‘0 0 * * 0’ ) 或手动触发 ( workflow_dispatch )。\n环境配置 ：自动安装 R 环境和必要的依赖（包括 rvest , tibble , tidyr 以及 clusterProfiler 自身）。\n执行更新 ：安装当前包后，完全按照我写好的 make updatedata 逻辑运行。\n自动 PR ：如果有文件变动（ .rda 文件更新），自动创建一个名为 update-kegg-data 的分支并提交 PR。\n\n我手动触发，试一下它work不work。显然是没有问题的，pull request已经正常出现。那么我只要merge就行了。做到数据每周定期检查，如有更新，就自动更新。\n\n好了，活人终究不能被尿憋死。\n后续\n终究我还是懒，KEGG更新还挺频繁的，我不想手工merge，再push到Bioconductor。于是数据和包分离，数据是预存没错，但不放在包里，而是放到github上，然后GitHub Actions自动更新。包里不带数据，总是从github上获取，这样最终可以做到不用管。"},"MyPackages/enrichplot/gseaplot2中的pvalue_table定制化":{"slug":"MyPackages/enrichplot/gseaplot2中的pvalue_table定制化","filePath":"MyPackages/enrichplot/gseaplot2中的pvalue_table定制化.md","title":"gseaplot2中的pvalue_table定制化","links":[],"tags":["enrichplot","GSEA","visualization"],"content":"\n来自于GitHub中的需求，两个问题：\n\n\n只画一条通路，不想要pvalue_table的rowname\n\n\n希望pvalue_table可定制，比如可以把NES放进去。\n\n\n先跑个示例：\nlibrary(DOSE)\ndata(geneList)\nx &lt;- gseDO(geneList)\n那么我在gseaplot2这个函数里加了两个参数，分别应对这两个问题：\n\n\npvalue_table_columns：用于指定什么信息放进表格里展示\n\n\npvalue_table_rownames：用于指定那个信息拿来当rownames\n\n\n默认行为保持不变：\ngseaplot2(x, 1, pvalue_table=T)\n\n去掉rownames，只需将pvalue_table_rownames设为NULL:\ngseaplot2(x, 1, pvalue_table=T, pvalue_table_rownames=NULL)\n\n可以指定rownames用什么信息，比如此处用ID，表格通过pvalue_table_columns可以自由指定：\ngseaplot2(x, 1, pvalue_table=T, \n    pvalue_table_rownames=&quot;ID&quot;, \n    pvalue_table_columns=c(&quot;NES&quot;, &quot;p.adjust&quot;))\n\n像上面这个图，也可以不要rownames，然后把这个信息放到table里：\ngseaplot2(x, 1, pvalue_table=T, \n    pvalue_table_rownames=NULL, \n    pvalue_table_columns=c(&quot;ID&quot;, &quot;NES&quot;, &quot;p.adjust&quot;))\n"},"MyPackages/enrichplot/p值的分布你考虑过没有？":{"slug":"MyPackages/enrichplot/p值的分布你考虑过没有？","filePath":"MyPackages/enrichplot/p值的分布你考虑过没有？.md","title":"p值的分布你考虑过没有？","links":[],"tags":["enrichplot","visualization","pvalue"],"content":"画图拿p值来上色，基本上很多人没有注意p值的分布，除非是工具培养了习惯，比如说火山图，p值就被转换成-10*log10(pvalue)，所有人就默认这样画，但换一个就不清不楚了。\n如果是一个随机的东西，去做检验，那p值的分布也会相对比较均一，或者是比较正态，均值在0.5附近之类的。\n这个我们都可以试一下的，拿随机的基因ID来搞个富集分析：\nrequire(clusterProfiler)\ndata(geneList, package=&quot;DOSE&quot;)\n \nset.seed(42)\nde2 = sample(names(geneList), 200)\n \ny = enrichGO(de2, OrgDb=&#039;org.Hs.eg.db&#039;)\nplot(density(y@result$p.adjust, bw=0.01))\n\n我们拿个差异基因来做富集的话，结果是不一样的。\nde &lt;- names(geneList)[1:200]\nx = enrichGO(de, OrgDb=&#039;org.Hs.eg.db&#039;)\nplot(density(x@result$pvalue, bw=0.01))\n\n就会有比较多的很小的p值，是一个偏态分布。\n比如我拿前面20条通路来画图，我们看一下p值的分布：\nplot(x@result$pvalue[1:20])\n\n这样拿去映射颜色的话，比如说红-蓝，结果就是尾部几个p值大点的是蓝色，其它的一片红色，区分不开。\n我们取个对数看看：\nplot(log10(x@result$pvalue[1:20]))\n\n区分度就有了。我们从整体上看的话，p值小的就被拉开了，p值大的，会聚集。\nplot(density(log10(x@result$pvalue), bw=0.01))\n\n所以如果只是单纯地把p值映射到颜色，就会是下面这两个图这样子，一片红区分不开。这样的图相信大家经常看到。\n\n\n所以我自己画图的时候，我是会对p值取对数来映射的。你看看我们2021年在The Innovation上发的clusterProfiler 4.0的文章，图全部是我操刀的。\n\n\n这些图的颜色区分度是有的。而画图的代码我是有提供的。大家可能没注意到这个细节，也就没有去抄我的代码。\n对于上面的x对象，你用dotplot()来画，出来的图是这样子的：\ndotplot(x)\n\n就是这样子红点多，且没有区分度。\n你是可以进行变换的。\ndotplot(x) + set_enrichplot_color(type=&#039;fill&#039;, transform=&#039;log10&#039;) \n出来的图就是这样子，有区分度了。\n\n这个功能很多人可能不知道。enrichplot中不同的图，配色一致，我不想要在不同的函数里有差不多的设置颜色代码，于是就写了这个set_enrichplot_color来统一设置颜色。它还是蛮好用的。比如说我想把颜色换成以前经典的红-蓝配色。只需要指定colors=c(&quot;red&quot;, &quot;blue&quot;)即可。\ndotplot(x) + set_enrichplot_color(type=&#039;fill&#039;, transform=&#039;log10&#039;, colors=c(&quot;red&quot;, &quot;blue&quot;))\n\n虽然长期以来，我们是可以对p值取对数的，但太多人不会用了，太多的图，都是一片红了。于是我决定在新的版本中，让取对数成为默认。所以如果你用了v&gt;=1.29.2，那么你用dotplot(x)出来的，就是取了对数的p值进行颜色映射的。\n你可能又会想，你全都要，新的默认你想要，旧的默认，你还想要，怎么办？简单，还是用set_enrichplot_color，你只要把transform=&quot;identity&quot;传入即可。也就是：\ndotplot(x) + set_enrichplot_color(type=&#039;fill&#039;, transform=&#039;identity&#039;) "},"MyPackages/ggtree/可交互的ggtree":{"slug":"MyPackages/ggtree/可交互的ggtree","filePath":"MyPackages/ggtree/可交互的ggtree.md","title":"可交互的ggtree","links":[],"tags":["ggtree","interactive"],"content":"\n\n开发ggtree就是我的使命！\n\n可交互这个功能是GISAID的创始人Peter Bogner和我提出来的，我们拉了个线上Zoom会议，聊了聊。于是我和双斌就着手来做这下事情。\n当我们做了个demo，发给他们的时候，跟我说，两周后WHO要开会选疫苗株，他们把数据整理了发我，我来帮他们画。\n\n这时候，我基本上就有求必应，乃至于说加班加点也要帮他们弄了。因为可以说，这是在给世界做贡献。\nggtree的交互，出现得悄无声息\nlibrary(ggtree)\n \n  \nset.seed(123)\ntr &lt;- rtree(20)\n# 这是静态的，和原来一样\np &lt;- ggtree(tr)\n \n# 交互开关，这第二个p，是可交互的图了\nggtree_set_interactive()\np\n\n就是这么简单，这是一个截图，所以看不出啥，但我们从红色框出来的地方，可以看到，这是一张html的【可交互】的图。\n当然这张图，事实上我们没有任何可交互的设置，它其实是没有交互元素的可交互图，有点绕口，但差不多可以说，搞了个寂寞。\n但它就是这么简单，有个开关，你开了，是交互的，关了，是静态的。你感觉不到它的存在。这就是我们所追求的，极致的简单，没有学习成本。\n就这个事情，双斌给我提了意见，说搞个寂寞这种，要给个warning。\n\n我给他的回复就是，搞个寂寞在某个场景下，或者是有用的。我再加个开关，可以关掉warning。\n\n没错，我们就是这么细节控，这样才做到了，呈现给大家的是极致的简单。\n怎么样可交互？\n你基本上只需要知道，加多了两个映射，就可以了：\n\ndata_id 为图形元素分配唯一标识符，用于JavaScript回调函数的元素识别，实现交互功能。\ntooltip 为图形元素添加鼠标悬停提示框，当鼠标悬停时，显示自定义信息。\n\n核心就这些，其它的以后再讲。\n让我们来看一个真正的可交互图：\np2 &lt;- ggtree(\n       tr,\n       mapping = aes(\n           tooltip = round(branch.length, 2),\n           data_id = node\n         )\n   )\n \np2\n代码简单吧，显示的信息是保留两个小数点的分支长度。\n\n鼠标悬停，信息出现，就这样简单。\n然后我们照常加图层，你可以在多个图层都设置有悬停，都是可以的。\ndt &lt;- data.frame(id = c(36, 38), type=c(&quot;A&quot;, &quot;B&quot;))\n \np3 &lt;- p2 +\n     geom_hilight(\n        data = dt,\n        mapping = aes(\n           node = id,\n           fill = type,\n           tooltip = paste0(&quot;clade of node &quot;, id),\n           data_id = type\n        ),\n        to.bottom = TRUE\n     )\n \np3\n\n眼尖的你可能发现，这张截图，高亮的区域和legend对应不上，其实是对着的，没有问题。你看到的不一样，是因为我截图的是鼠标正好悬停在上面，鼠标悬停会高亮相应的图形元素，就像上一张图，在分支上，那个分支就有了颜色一样，所以相当于叠多了个颜色，就看着不一样。当我们把鼠标移开之后，它就是原来的颜色，是一模一样的。\n然后可交互图，一般不是只给你导出PNG, SVG这些，不给保存PDF？\n让我们把交互特性给关了。\nggtree_unset_interactive()\n \np3\n\n这就是美妙之处，零学习成本，静态与交互，随意切换。"},"MyPackages/mirrorselect/包不存在！镜像要不要背锅？":{"slug":"MyPackages/mirrorselect/包不存在！镜像要不要背锅？","filePath":"MyPackages/mirrorselect/包不存在！镜像要不要背锅？.md","title":"包不存在！镜像要不要背锅？","links":[],"tags":["mirrorselect","R"],"content":"一条指令装一下ggplot2，它竟然告诉我没这个包，这难道不是在欺负我？\n&gt; install.packages(&quot;ggplot2&quot;)\nInstalling package into ‘E:/software-data/RLibrary’\n(as ‘lib’ is unspecified)\nWarning: unable to access index for repository mirrors.ustc.edu.cn/CRAN/src/contrib:\n  cannot open URL &#039;mirrors.ustc.edu.cn/CRAN/src/contrib/PACKAGES&#039;\nWarning: unable to access index for repository mirrors.ustc.edu.cn/CRAN/bin/windows/contrib/4.5:\n  cannot open URL &#039;mirrors.ustc.edu.cn/CRAN/bin/windows/contrib/4.5/PACKAGES&#039;\nWarning message:\npackage ‘ggplot2’ is not available for this version of R\n \nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\ncran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages \n怀疑人生，想起我6年前写的魔镜mirrorselect包（电梯：《魔镜魔镜告诉你，它上CRAN了》），果断测速，换个镜像。\n&gt; mirrorselect::get_mirror(&#039;CRAN&#039;, &#039;cn&#039;) -&gt; m\n&gt; head(m)\n[1] &quot;mirrors.tuna.tsinghua.edu.cn/CRAN/&quot; &quot;mirrors.bfsu.edu.cn/CRAN/&quot;          &quot;mirrors.pku.edu.cn/CRAN/&quot;          \n[4] &quot;mirrors.ustc.edu.cn/CRAN/&quot;          &quot;mirrors.zju.edu.cn/CRAN/&quot;           &quot;mirrors.qlu.edu.cn/CRAN/&quot;          \n&gt; length(m)\n[1] 12\n&gt; mirrorselect::mirrorselect(m) -&gt; st\n&gt; st\n                                       mirror speed\n1           mirrors.hust.edu.cn/CRAN/  0.13\n2           mirrors.ustc.edu.cn/CRAN/  0.14\n3        mirrors.sustech.edu.cn/CRAN/  0.14\n4            mirrors.pku.edu.cn/CRAN/  0.18\n5            mirrors.nju.edu.cn/CRAN/  0.23\n6             mirror.lzu.edu.cn/CRAN/  0.26\n7     mirrors.sjtug.sjtu.edu.cn/cran/  0.27\n8          mirrors.nwafu.edu.cn/cran/  0.28\n9            mirrors.zju.edu.cn/CRAN/  0.32\n10           mirrors.qlu.edu.cn/CRAN/  0.41\n11          mirrors.bfsu.edu.cn/CRAN/  0.53\n12 mirrors.tuna.tsinghua.edu.cn/CRAN/  0.55\n看上去华科最快，换上再试试，装包就丝滑了。\n&gt; options(repos = c(CRAN = &quot;mirrors.hust.edu.cn/CRAN/&quot;))\n&gt; install.packages(&quot;ggplot2&quot;)\nInstalling package into ‘E:/software-data/RLibrary’\n(as ‘lib’ is unspecified)\ntrying URL &#039;mirrors.hust.edu.cn/CRAN/bin/windows/contrib/4.5/ggplot2_3.5.2.zip&#039;\nContent type &#039;application/zip&#039; length 5016803 bytes (4.8 MB)\ndownloaded 4.8 MB\n \npackage ‘ggplot2’ successfully unpacked and MD5 sums checked\n \nThe downloaded binary packages are in\n        C:\\Users\\HUAWEI\\AppData\\Local\\Temp\\RtmpS8YcTh\\downloaded_packages\n\nCRAN包，用install.packages(&quot;mirrorselect&quot;)就可以安装，让你下包接上大水管。"},"MyPackages/swissmodel/为了上课，给Swiss-Model写个R包吧":{"slug":"MyPackages/swissmodel/为了上课，给Swiss-Model写个R包吧","filePath":"MyPackages/swissmodel/为了上课，给Swiss-Model写个R包吧.md","title":"为了上课 - 给Swiss-Model写个R包吧","links":[],"tags":["swissmodel","R","protein-structure"],"content":"Swiss-Model是啥？\n来自说明文档的介绍：\n\nSWISS-MODEL is a web-based integrated service dedicated to protein structure homology modelling. It guides the user in building protein homology models at different levels of complexity.\nBuilding a homology model comprises four main steps: (i) identification of structural template(s), (ii) alignment of target sequence and template structure(s), (iii) model-building, and (iv) model quality evaluation. These steps require specialised software and integrate up-to-date protein sequence and structure databases. Each of the above steps can be repeated interactively until a satisfying modelling result is achieved.\n\n使用很简单，Web Sever里贴序列就行：\n\n为什么要写个R包？\n上实验课，要使用Swiss-Model进行蛋白质建模，其它的操作都在R里可以搞，但这一步，得到网页上来弄，再把结果下载下来，又回到R。就想问自己一个问题：能不能装逼装全套？于是就着手写一个R包。\n安装\n一条指令安装：\nyulab.utils::install_zip_gh(&quot;YuLab-SMU/swissmodel&quot;)\n设置\n首先是需要一个API token，注册了在账号里就可以看到：\n\n然后加载swissmodel包，用set_swissmodel_token函数设置即可。\nlibrary(swissmodel)\nset_swissmodel_token(&quot;YOUR_SWISSMODEL_TOKEN&quot;)\n建模\n首先你得有序列吧：\nhemoglobin_sequence &lt;- &quot;VLSPADKTNVKAAWAKVGNHAADFGAEALERMFMSFPSTKTYFSHFDLGHNSTQVKGHGKKVADALTKAVGHLDTLPDALSDLSDLHAHKLRVDPVNFKLLSHCLLVTLAAHLPGDFTPSVHASLDKFLASVSTVLTSKYR&quot;\n然后建模直接是写成一个workflow，所以你只要跑这一句代码就行：\nresult &lt;- run_automodel_workflow(hemoglobin_sequence)\n然后就是等，期间函数打印出来的信息如下：\nStarting automodel workflow...\nAUTOMODEL task submitted successfully!\nProject ID: 25f307\nProject status: INITIALISED [Waited: 0 seconds]\nProject status: RUNNING [Waited: 32 seconds]\nProject status: RUNNING [Waited: 63 seconds]\nProject status: RUNNING [Waited: 95 seconds]\nProject status: RUNNING [Waited: 127 seconds]\nProject status: RUNNING [Waited: 158 seconds]\nProject status: RUNNING [Waited: 189 seconds]\nProject status: RUNNING [Waited: 220 seconds]\nProject status: RUNNING [Waited: 251 seconds]\nProject status: RUNNING [Waited: 282 seconds]\nProject status: COMPLETED [Waited: 313 seconds]\nModeling completed successfully!\nFile downloaded successfully: ./modeling_results/25f307_model_1.pdb\nFile downloaded successfully: ./modeling_results/25f307_model_2.pdb\n这个workflow包含了几步：\n\n\n创建一个输出的文件夹，默认./modeling_results\n\n\n提交序列，得到一个项目ID\n\n\n检查这个项目的状态\n\n\n当项目完成之后，拿到结果的URL\n\n\n下载文件\n\n\n返回运行整个workflow的一些相关信息\n\n\nresult里记录了相关的信息，结果如下：\n&gt; result\n$project_id\n[1] &quot;25f307&quot;\n \n$status\n[1] &quot;COMPLETED&quot;\n \n$downloaded_files\n$downloaded_files$model_1\n[1] &quot;./modeling_results/25f307_model_1.pdb&quot;\n \n$downloaded_files$model_2\n[1] &quot;./modeling_results/25f307_model_2.pdb&quot;\n \n$project_info_file\n[1] &quot;./modeling_results/25f307_info.json&quot;\n这些信息也会被写入json文件，这样你退出R之后，这些信息都是有保留的。这个json文件的信息很容易读进来：\n&gt; jsonlite::fromJSON(result$project_info_file)\n$project_id\n[1] &quot;25f307&quot;\n \n$status\n[1] &quot;COMPLETED&quot;\n \n$models\n  model_id    status gmqe                                               coordinates_url                                                  modelcif_url avg_local_score\n1       01 COMPLETED 0.98 swissmodel.expasy.org/project/25f307/models/01.pdb.gz swissmodel.expasy.org/project/25f307/models/01.cif.gz              NA\n2       02 COMPLETED 0.90 swissmodel.expasy.org/project/25f307/models/02.pdb.gz swissmodel.expasy.org/project/25f307/models/02.cif.gz            0.85\n \n$date_created\n[1] &quot;2025-11-10T05:54:31.192032Z&quot;\n \n$project_title\n[1] &quot;R Automodel&quot;\n \n$view_url\n[1] &quot;swissmodel.expasy.org/project/25f307/view&quot;\n这个view_url点开之后，也可以到Swiss-Model网站上看结果：\n\n所以一个流程，完事了。建模完成的pdb文件已经下载到了本地，我们可以在R里读取。\n这个R包到这里，应该说就完成了开头说的，要在R里用Swiss-Model的使命。演示的这个流程，里面每一步都是可以单独运行的，函数都是分开并且是export的。\n蛋白结构初印象\n我还继续写了一些简单的函数，可以做一些简单的分析。\n首先读取PDB文件，调用了bio3d包的read.pdb:\n&gt; pdb = read.pdb(result$downloaded_files[[1]])\n然后你可以用summary来看这个对象的一些信息：\n&gt; summary(pdb)\n \n Call:  read.pdb(file = result$downloaded_files[[1]])\n \n   Total Models#: 1\n     Total Atoms#: 1076,  XYZs#: 3228  Chains#: 1  (values: A)\n \n     Protein Atoms#: 1076  (residues/Calpha atoms#: 141)\n     Nucleic acid Atoms#: 0  (residues/phosphate atoms#: 0)\n \n     Non-protein/nucleic Atoms#: 0  (residues: 0)\n     Non-protein/nucleic resid values: [ none ]\n \n+ attr: atom, xyz, calpha, call\n在swissmodel包里，也提供了其它一些函数，包括pdb_info():\n&gt; pdb_info(pdb)\nProtein Structure Information:\n  - Atoms: 1076\n  - Residues: 141\n  - Chains: A\n  - Model dimensions (&lt;c3&gt;&lt;85&gt;):\n    X: 43.88\n    Y: 27.32\n    Z: 41.17\n$atoms\n[1] 1076\n \n$residues\n[1] 141\n \n$chains\n[1] &quot;A&quot;\n \n$dimensions\n     x      y      z \n43.883 27.317 41.168 \n以及analyze_model_quality():\n&gt; analyze_model_quality(pdb)\n$atoms\n[1] 1076\n \n$residues\n[1] 141\n \n$chains\n[1] &quot;A&quot;\n \n$resolution\n[1] NA\n \n$rama_favored\n[1] 79.28571\n \n$rama_allowed\n[1] 9.285714\n \n$rama_outliers\n[1] 11.42857\n它会计算拉式图的一些参数：\n\n\nRamachandran Favored（最允许区域）：这些区域对应的φ和ψ二面角组合在立体化学上是最允许的，通常对应于蛋白质中常见的二级结构，如α-螺旋和β-折叠。这些区域内的残基构象在能量上是有利的，且没有原子间的空间冲突。\n\n\nRamachandran Allowed（允许区域）：这些区域对应的φ和ψ二面角组合在立体化学上是允许的，但可能不如最允许区域那么理想。这些区域内的残基构象在能量上可能是可接受的，但可能不如最允许区域稳定。\n\n\nRamachandran Outliers（异常区域）：这些区域对应的φ和ψ二面角组合在立体化学上是不允许的，因为它们会导致原子间的空间冲突或能量上不利的构象。出现在这些区域的残基可能表示该残基的构象存在问题，例如在蛋白质结构建模或测定中可能出现了错误。\n\n\n画图\n拉式图（Ramachandran图）来评估蛋白质结构中氨基酸残基的构象是否合理。Ramachandran图是根据蛋白质中每个非末端氨基酸残基的φ和ψ二面角绘制的散点图。这些二面角决定了蛋白质主链的构象。\n也是一条指令：\nplot_ramachandran(pdb)\n\n还可以画一下残基的组成：\nplot_residue_composition(pdb)\n\n最后呢，三维结构不画三维怎么行，还是一条指令：\nplot_pdb(pdb)\n\n这里调用了以前介绍的R包r3dmol。\n对于这些结构简单分析和画图函数，也封装成一个流程，只需要跑run_pdb_analysis()一个函数，就会将这些分析全部跑一遍，然后分别写入文件。\n参考资料\n\nswissmodel.expasy.org/docs/help\n拉氏图: zh.wikipedia.org/wiki/%E6%8B%89%E6%B0%8F%E5%9B%BE\n在R中对分子结构进行3D可视化: mp.weixin.qq.com/s/lOfc6ZRFBI3EWoSgpd5guw\n"},"Tools/Obsidian-Quartz博客系统":{"slug":"Tools/Obsidian-Quartz博客系统","filePath":"Tools/Obsidian-Quartz博客系统.md","title":"Obsidian-Quartz博客系统","links":[],"tags":["blog","quartz","obsidian","github"],"content":"创建Quartz博客\nQuartz是使用Node.js的，所以首先是需要安装Node.js：\nscoop install nodejs-lts\n从github.com/jackyzha0/quartz下载。然后是安装依赖：\nnpm install\n然后就可以创建博客了：\nnpx quartz create\n与Obsidian的联动\n平时用Obsidian来写东西，但并不是写啥，都会公开。所以对于是否要公开，用一个YAML frontmatter做为开关。\n---\npublish: true\n---\n\ntrue是要发表的，false是不发表的。\n但是Quartz默认是不管的，它并不去识别publish: false这个字段，我们需要修改quartz.config.ts，找到这一段：\nimport * as Plugin from &quot;./quartz/plugins&quot;\n \nconst config: QuartzConfig = {\n  configuration: {\n    // ...\n  },\n  plugins: {\n    transformers: [\n      Plugin.FrontMatter(),\n      // ...\n    ],\n    filters: [\n      // 这里通常有一些默认的 filter，比如 RemoveDrafts 之类的\n    ],\n    emitters: [\n      // ...\n    ],\n  },\n}\n \nexport default config\n在filters里面加上Plugin.ExplicitPublish():\nfilters: [\n  Plugin.ExplicitPublish(),\n  // 如果你还有其他 filter，就按需要保留\n  // Plugin.RemoveDrafts(),\n],\n这样子，就会只发布publish: true的markdown文件。\n构建博客\n设置好之后，就可以用obsidian中的文档来生成博客了，用以下指令：\n# 如需要本地预览，加上  --serve\nnpx quartz build -d ../YuNotebooks -o docs\n\n输入直接用上一层目录的obsidian vault，我的笔记在本地，而生成的博客，只有我标识了publish: true的部分，输入的html文档，就放到docs文件夹里，方便后面在GitHub上指定它为Pages。\n但是这里还是有一个问题，就是publish: false的md虽然不会被渲染，但是对应的assets文件夹（放图片，用的Custom Attachment Location）这些还是会被拷贝到docs目录下，必须要写个脚本来清除它，于是就写了一个cleanup_public_no_html.py的脚本。\n然后还有一个问题，就是插入的图片是![](assets/xxx)这种形式，在把md渲染成html的时候，它会把这个目录当成是根目录下的，结果就是md文件如果放一层目录，就会变成../assets/xxx，放两层目录下，就会变成../../assets/xxx，这样子图片就会显示不正常，又需要写一个脚本，correct-image-path.py来读取生成的html文件，修改一下路径。\n发布博客\n到这里就没啥了，推送到GitHub，把docs目录选为Pages，打完收工。\n做个懒人\n还想更进一步，毕竟是和Obsidian联动，就是我只管在Obsidian里写笔记，不用管博客，这是最好的，笔记反正是可以控制是否发表，不需要每次我想发表，就得来弄一下。所以笔记我放到private repo里。搞个Secret，让Actions可以拉取，然后该怎么跑，让Actions去弄。然后我再设置，每天北京时间早上3:00自动跑一次Actions，这样子，我压根不用管博客，只管笔记。笔记也是设置好的，自动同步到GitHub。\n所以整个逻辑就是：\n\n我只管本地写笔记\n后台自动同步GitHub\nActions自动更新博客\n\n然后我只需要做第一步，完美。\n后续更新\n由于原来的repo是来自quartz仓库，它是MIT协议的，也不好改它的。但我的博客放在docs目录下，用MIT协议是不合适的。于是还是分开分支，让quartz的东西，保持MIT协议，里面包含quartz的配置、样式、构建脚本（当然也包括我自己的脚本和Workflow Actions）。\n\n新建一个gh-pages分支，包含博客的内容，用CC BY-NC-ND 4.0协议。\n\ngit checkout --orphan gh-pages \ngit rm -rf . \n \ntouch README.md \ngit add README.md \ngit commit -m &quot;Initial commit for gh-pages&quot;\ngit push -u origin gh-pages\n\n回到main分支：\n\n修改quartz/components/Footer.tsx ，在博客页面底部添加了 CC 协议链接，明确告知读者内容版权。\n        &lt;p&gt;\n          Content licensed under &lt;a href=&quot;creativecommons.org/licenses/by-nc-nd/4.0/&quot;&gt;CC BY-NC-ND 4.0&lt;/a&gt;\n        &lt;/p&gt;\n修改[Workflow](ygc-blog/.github/workflows/deploy-from-private-content.yaml at main · YuLab-SMU/ygc-blog)，把原来同步内容到docs和推送的步骤，变成用peaceiris/actions-gh-pages发布到gh-pages分支。这个gh-pages分支里自动加入LICENSE文件，声明CC BY-NC-ND 4.0协议。\n这样就做到了，代码和内容分离，并使用不同的协议。"},"Tools/一个快捷键搞定远程执行":{"slug":"Tools/一个快捷键搞定远程执行","filePath":"Tools/一个快捷键搞定远程执行.md","title":"一个快捷键搞定远程执行","links":[],"tags":["vscode","positron","remote"],"content":"你有没有这种场景：\n\n本地写代码，远程服务器跑任务（R / Python / Shell 都行）\n服务器环境不好配，装一堆后端、插件、依赖还要翻墙\n你其实只想要一个最朴素的能力：把编辑器里选中的几行，发到远程终端执行\n\n我最近在折腾 Positron 的远程能力时，又一次意识到：有些“高级集成”当然很香，但在很多时候，一个简单的快捷键就能把 80% 的问题解决掉。\n先说 Positron 的官方远程思路\n上次写下《见异思迁：扔掉RStudio，拥抱Positron》时，我想：Positron 现在应该已经把远程 R 给配置好了吧？于是去搜了一圈。\n确实是有的，是以下这样的工作形式：\n\n需要服务器端有个Positron Backend，它在你第一次用的时候，需要装一下东西：\n\n然后我试了一下，下载需要翻墙。\n\n我本来想找镜像，或者先在本地下载再上传到服务器，最后 ssh 上去手工装。一搜，倒是看到有人在 GitHub 上给了另一种路线：\n\n这个方案不是解决 positron backend 的安装问题，而是用 openvscode-server 来当 backend，相当于把 positron backend 换掉。自己折腾当然有机会跑通，但我这次没有继续往下钻。\n退一步：回到最朴素、最可靠的方案\n我突然想起以前用 Emacs 的日子：在编辑器里开一个 terminal，ssh 到服务器，再启动服务器端的 R（或 Python）。之后我在编辑器里写代码，把选中的代码“发送到终端”，就等于在远程解释器里执行了。\n整个过程完全不依赖服务器端做任何额外配置，本质上就是：\n\n\n终端在哪里不重要（本地/远程都可以）\n\n\n解释器是什么不重要（Shell/R/Python 都可以）\n\n\n我只需要一个动作：把代码发过去执行\n\n\n在Positron里，Ctrl+Enter 会把代码发送到 Console（例如 R 或 Python）。那我只要定义一个快捷键，把“选中的文本”发送到 Terminal 执行，就能实现上面的流程。\n一个快捷键：Shift+Enter 把选中内容发到终端\n我定义了一个 Shift+Enter 的快捷键：\n    {\n        &quot;key&quot;: &quot;shift+enter&quot;,\n        &quot;command&quot;: &quot;workbench.action.terminal.runSelectedText&quot;,\n        &quot;args&quot;: { &quot;text&quot;: &quot;${selectedText}\\\\n&quot; },\n        &quot;when&quot;: &quot;editorTextFocus&quot;\n    }\n有了它之后，编辑器里选中一段代码，按一下 Shift+Enter，就会把内容发到当前 Terminal 执行。这个 Terminal 不管是本地还是远程，不管跑的是 Shell、R 还是 Python，都适用。\n\n使用体验：朴素，但真的好用\n配合 screen、nohup 之类的工具，你就能做到：脚本在本地写，任务在服务器跑。即便你不做远程开发，这个快捷键也很值：很多时候我们想在 Terminal 执行几条命令，往往是在终端里现敲；有了这个套路，你更容易把命令写成“可复用的文本”，一键发送执行。\n这种“以文本为核心”的工作方式有点 Emacs 的味道：看起来不 fancy，但非常稳定、通用、可迁移。最重要的是，它让你不必为了一个简单需求，去背负一整套复杂配置。"},"Tools/生信语言之争的真相":{"slug":"Tools/生信语言之争的真相","filePath":"Tools/生信语言之争的真相.md","title":"生信语言之争的真相：不是语法，是生态","links":[],"tags":["R","perl","python"],"content":"很多人都有一个共识：Python 取代了 Perl。我的看法更像是：Python 当然赢了，但它未必是“在 Perl 的主场赢的”，更多时候是战场换了，用户迁移了。\n如果只用一句话总结：生信语言的胜负，很少发生在“语法”和“哲学”，更多发生在“谁把地基修好、谁让协作变得省力”。\n先把“生态”说清楚：它到底指什么\n说生态，不是指“包多”，而是指一套能让大多数人顺滑完成工作的共同约定。它通常至少包含这些维度：\n\n数据容器与标准：有没有主流的数据结构承载真实数据（带元信息、带注释、带版本语义），并且被大多数工具默认支持。\n互作性：包与包之间能否无缝拼起来（输入输出一致、语义一致、边界清晰），而不是每一步都在做格式转换。\n可复现与分发：依赖是否能被稳定安装、锁定、迁移；论文里的方法是否能被别人可靠跑出来。\n性能与扩展路径：慢的部分有没有“正确的后端”可用（C/C++/CUDA、磁盘后端、并行后端），并且被上层工具透明复用。\n教学与文档：是否进入课堂与教材；是否有足够多的示例、最佳实践、踩坑经验沉淀。\n治理与长期维护：关键基础设施是否有人守护，API 变化是否克制，老代码是否能活得久。\n\n下面再回头看“Perl→Python”的说法，你会发现它常常把真正发生的事情给说扁了。\n主场迁移：不是谁打败了谁，而是谁换了战场\n可以粗略把生信主战场分成三个阶段：\n\n基因组时代：序列与文本是主角。FASTA/FASTQ、注释、日志、报表，核心能力是文本处理与脚本胶水。\n组学时代：统计建模与下游分析是主角。差异分析、富集分析、可视化、整合分析，核心能力是统计框架与可组合工具链。\n工程化与 AI 时代：更大的计算与更复杂的系统是主角。数据工程、部署、GPU、模型生态，核心能力是工程与算力栈的整合。\n\n这三段里，语言各自的“主场”并不相同。\nPerl 为什么曾经那么强\nPerl 在基因组时代的爆火是有原因的：文本处理就是它的强项。在大量 FASTA/FASTQ、注释文本、各种日志与报表的年代，Perl 的表达力与效率都非常能打；很多时候，Python 在纯文本处理速度上确实吃亏。\n更重要的是，Perl 当年有 BioPerl 这样成体系的生态支撑：围绕生物序列处理形成了一套基础设施与约定。多年过去，Python 在生物学领域当然积累了很多工具，但在“当年 BioPerl 那种以生物序列处理为中心、覆盖面很全的一揽子基础设施”上，确实很难说出现了同等地位、同等覆盖面的替代。\n真正的转折：组学时代的赢家往往是 R\n后基因组/功能基因组时代到来，尤其是转录组学兴起后，生信日常从“处理序列文本”转向“做统计建模与组学分析”。这个阶段的最大赢家，往往不是 Python，也不是 Perl，而是 R。\nR 能在组学里站稳，核心在 Bioconductor：它不只是“很多包”，而是一套基础设施先把路修好，尤其是数据容器与共同约定，然后无数包在同一块地基上生长、互相协作。到今天，它依然是组学分析里非常难撼动的生态。\n一个微型例子：做完分析到底顺不顺\n以常见任务为例：从表达矩阵与临床表开始，做 QC、归一化、差异分析、富集分析、可视化，最后生成可复现报告。这里的体验差异，往往不在“哪个语言更优雅”，而在：\n\n你的对象能否在每一步都保留元信息与注释，并被下游默认识别。\n你是否需要在每一步都重新对齐样本、重命名列、重写输出格式。\n你做的图是否能自然接入同一套语义与可组合层级。\n\n单个 Python 项目可能非常亮眼；但当你把多个项目拼到一整条分析流水线里时，“互作性”和“共同约定”往往才是决定体验的关键。\n那 Python 凭啥赢？\n如果问“Python 凭啥赢”，答案更像是：它赢在更大的科学计算与工程生态里，尤其是把大量 C/C++ 核心库、数据工程与 AI 栈粘在一起的能力。\n靠 AI？在 AI 大火之前，Perl 在很多团队里就已经不再是首选了。\n靠 NumPy / pandas 的数据科学生态？靠 scikit-learn 的机器学习？这些都很关键，但历史并不算长；而当它们真正形成势能的时候，Perl 的浪潮早已退下去。\n也可以把 Python 放在更贴近现实的位置：它更像一门强大的“工程胶水语言”，把数据、计算、部署、可视化、模型训练串成一个系统。\n还有一张经常被低估的牌：语法简单与教学普及。当一种语言进入课堂，它就会持续产出“能用它的人”。开发者基数一大，文档、教程、问答与工程实践会自然滚起来；很多团队的技术选型，也会在“更容易招人、交接成本更低”的现实因素下倾向 Python。\n反过来想：Python 一定能“吃掉 R”吗？\n在单细胞等方向，scverse/scanpy 等生态非常强，也确实承载了大量真实工作流。但“强”并不必然意味着“替代”：很多时候，它更像是在某些子场景里建立了高效的体系；而当你把视角拉到更广泛的组学分析、方法学沉淀与跨包互作时，Bioconductor 那套“容器+约定”的优势仍然很难被简单复刻。\n至于单细胞分析里大家常吐槽的“R 扛不住”，更多是某些工作流和实现方式带来的观感，不必简单归因到语言本身。Bioconductor 在单细胞方向也有一套可扩展的设计（例如 DelayedArray 这种前端抽象，后端可以接 HDF5，但不限于 HDF5）。\n所以：Python 取代 Perl？还是用户跑去用 R？\n于是我会更愿意把它说成：虽然大家口头上说“Python 取代了 Perl”，但在生物信息学里，很多时候更像是用户从 Perl 的主场，整体迁移到了 R 的主场；而 Python 则在更大的科学计算与工程生态里，成为了更强的“胶水语言”。\n把 Python 和 Perl 拿出来对比，其实也因为它们都经常被定位成“胶水语言”。如果一定要在 Perl 擅长的领域硬 PK，“Python 语法简单”“只有一种显式解”这类口号并不构成决定性优势；语言的成功与否，往往不是靠几句哲学宣言能解释清楚的。\n更现实的一点是：当一种语言赢了，世界会自动帮它补齐一套“赢的理由”；当一种语言失势，它再多的优点也会被写成“门槛”或“历史包袱”。这并不稀奇。\n生态才是胜负手：大家都活在生态里\n真正决定胜负的，通常是生态：有没有人把地基搭好，有没有足够多的用户把场景填满。\n历史上，很多语言的崛起都离不开“出道就带的基础设施”：Java 的类库、Perl 的 BioPerl、R 的 Bioconductor、Python 在 AI 时代的 TensorFlow/PyTorch……都说明了同一件事：只要生态把大多数人照顾好，它就会赢。\n至于“脚本语言依赖复杂、调包侠”的吐槽，在生信领域确实常见。但这往往不是脚本 vs 编译型的本质区别，更像是依赖管理的普遍难题：C/C++ 也经常遇到 .so/.dll/.dylib 找不到或版本冲突，只是大家习惯把它叫做“系统环境问题”。换个语言，本质还是同一道题。\n\n换个更大视角：Perl 没死，只是退居“系统底层”\nPerl 的文本处理强，也让它在早期 Web 开发里有过重要位置；后来上不及 Java 的企业级光环，下不如 PHP 的简单粗暴。与此同时，Python 并没有在这条赛道上和 Perl 正面对撞，而是更用力地去“卷”科学计算：它把大量 C/C++ 核心库粘在一起，连接起更大的世界。等到 NumPy、SciPy 等核心库站稳脚跟，再叠加数据科学与 AI 的东风，Python 的优势就滚雪球一样放大。\n而 Perl 呢？它并没有“消失”。几乎没有哪个 *nix 系统不预装 Perl，在系统管理和很多底层脚本里，它依然随处可见。这是一种强大到有点可怕的生态惯性：你以为它退场了，但它一直在那里。\n结尾：怎么选，其实是“分层协作”\n我更愿意把结论写得直白一点：不是谁取代了谁，而是用户在不同阶段选择了更适合的工具；而工具能否被选择，很大程度取决于它背后的生态是否恰好解决了你的问题。\n如果要给一个实用的选择框架，大概是这样：\n\n以统计方法学与组学分析为中心：R 往往更顺手，尤其是 Bioconductor 体系内的工作流。\n以工程化、部署、数据管道与 AI 训练为中心：Python 往往更强，且能连接更大的计算与工程生态。\n以高性能与通用可移植为中心：把关键瓶颈交给更底层的实现，再由上层语言做胶水与交互。\n\n生态的构建，一方面需要少数人把地基搭好，另一方面需要大量用户把真实场景填进去。一个时代有一个时代的需求，也会造就一个时代的英雄。Perl 是旧时代的英雄；R 在组学时代影响力巨大；Python 则在更广阔的科学计算与 AI 时代加速扩张。至于未来谁会更强，看需求怎么变，也看生态怎么长。\n最后搬运一下 @tangming2005 的推文：反正我也不是那个能“打地基”的人，谁的生态更能满足我的需求，我就更愿意跟谁混。\n\n\n\n"},"Tools/见异思迁：扔掉RStudio，拥抱Positron":{"slug":"Tools/见异思迁：扔掉RStudio，拥抱Positron","filePath":"Tools/见异思迁：扔掉RStudio，拥抱Positron.md","title":"use-positron","links":[],"tags":["R","positron","vscode"],"content":"定制版不香吗？\n虽然标题是扔掉RStudio，但我使用RStudio的时间其实非常有限，基本上只有我需要讲课演示的时候，才会安装在课堂上用一下。用了二十年的R，有十几年的时间是在Emacs中使用R的：\n\n后来我一直用一个定制的版本叫SPACEMACS，定制的就是香，省心。\n这几年转向使用VSCODE，平时用着也挺爽的，但是现在有Positron，还是那句话，定制版本省心，于是喜新厌旧。\nBash\n安装之后，TERMINAL打开是CMD，这可不行，我一惯是用bash的。打开settings.json是这样子的：\n{\n    &quot;python.defaultInterpreterPath&quot;: &quot;E:\\\\software-data\\\\scoop\\\\apps\\\\miniconda3\\\\current\\\\python.exe&quot;,\n    &quot;launch&quot;: {\n        &quot;configurations&quot;: [\n          \n            \n \n        ]\n    },\n \n    &quot;Bash&quot;: {\n        &quot;source&quot;: &quot;Bash&quot;,\n        &quot;args&quot;: [],\n        &quot;icon&quot;: &quot;terminal-bash&quot;,\n        &quot;path&quot;: &quot;E:\\\\software-data\\\\scoop\\\\shims\\\\bash.exe&quot;\n      }\n    },\n    &quot;terminal.integrated.defaultProfile.windows&quot;: &quot;Bash&quot;,\n    &quot;launch&quot;: {\n      &quot;configurations&quot;: [\n      \n      ]\n    }\n}\n它里面有bash，不知道是不去去抄了我的VSCODE配置，但是配置又不对，有一个花括号对不上，于是终端就找不到Bash选项。参考一下我在VSCode的设定，改为以下内容：\n{\n    &quot;python.defaultInterpreterPath&quot;: &quot;E:\\\\software-data\\\\scoop\\\\apps\\\\miniconda3\\\\current\\\\python.exe&quot;,\n    &quot;terminal.integrated.env.windows&quot;: {},\n    &quot;terminal.integrated.profiles.windows&quot;: {\n    &quot;Bash&quot;: {\n        &quot;source&quot;: &quot;Bash&quot;,\n        &quot;args&quot;: [],\n        &quot;icon&quot;: &quot;terminal-bash&quot;,\n        &quot;path&quot;: &quot;E:\\\\software-data\\\\scoop\\\\shims\\\\bash.exe&quot;\n      }\n    },\n    &quot;terminal.integrated.defaultProfile.windows&quot;: &quot;Bash&quot;,\n    &quot;launch&quot;: {\n      &quot;configurations&quot;: [\n      \n      ]\n    }\n}\nBash就出来了。我不单在Windows里有bash，还配置得比较好看。\n\nR\n一打开，Positron能发现我有好多个python环境，但是R却找不到，主要是它在特定的安装路径和注册表以及RStudio的配置中去找，在我这通通找不到。\n我安装R稍微比较另类，请猛击《Windows下新装R的极简指南》，只要在配置中，把R的根目录给设定好就行，也还算比较简单。\n顺道吐槽，网上一堆代码，都告诉你，干啥先来一句rm(list=ls())，说是让你的R环境干净，本身一直在RStudio里不出来的所谓跑脚本，就是一个悖论。RStudio一打开，已经不干净了。你看我下面的截图，我一打开R，也已经不干净了。除了ASCII图和名人名言，一打开R已经加载了很多东西。我跑脚本，从来没有这一句rm(list=ls())，而是区分交互使用R和用R跑脚本两件事：一个是平时交互使用加一堆预设，让自己爽；一个是跑脚本追求干干净净，避免别人用脚本的时候，因环境不一致而出错，让别人爽。\n\n开箱稍微弄一下，Bash有了，R能用，Python能用，就OK了。相信专业人士的定制，会让我们用起来省心省力一些，其它的，其实和VSCODE没两样，因为就是一张皮。\n平时编辑文件习惯用code filename来打开，现在要用positron来打开，就得变成positron filename，为了照顾肌肉记忆，只需要在.bashrc里加入alias code=&quot;positron&quot;即可。"},"index":{"slug":"index","filePath":"index.md","title":"Guangchuang Yu's Blog","links":[],"tags":[],"content":"欢迎来到余光创的博客，主要记录本人在科研工作中的一些经验与思考、科研进展和学习笔记。\n课题组主页\n\n主页：yulab-smu.top/\nGitHub：github.com/YuLab-SMU\n\n课题组公众号\n欢迎关注课题组 公众号：YuLabSMU。"},"可视化/用-R-语言把“屎”画出来：数据可视化的极端案例":{"slug":"可视化/用-R-语言把“屎”画出来：数据可视化的极端案例","filePath":"可视化/用 R 语言把“屎”画出来：数据可视化的极端案例.md","title":"用 R 语言把“屎”画出来","links":[],"tags":["R","visualization","3D","rgl"],"content":"知乎上的帖子，说MATLAB画的shit都比Python好看：\n\n\n我想可以翻译成R来画一下，先照着写一个产生数据的函数：\nshitshape &lt;- function(points = 400, circle_pts = 40) {\n  linspace &lt;- function(a, b, n) seq(a, b, length.out = n)\n \n  cross3 &lt;- function(a, b) {\n    c(\n      a[2] * b[3] - a[3] * b[2],\n      a[3] * b[1] - a[1] * b[3],\n      a[1] * b[2] - a[2] * b[1]\n    )\n  }\n \n  normalize &lt;- function(v) {\n    v / sqrt(sum(v * v))\n  }\n \n  z &lt;- linspace(0, 1, points)\n  z[1:50] &lt;- z[1:50] + z[50] * linspace(1, 0, 50)\n  z[201:400] &lt;- z[201:400] - 0.12 * linspace(0, 1, 200)\n \n  s &lt;- linspace(0, 1, points)\n \n  path_radius &lt;- linspace(0.7, 0.02, points) * (cos(linspace(0, pi / 2, points)) + 1.5) / 3.5\n \n  tube_radius &lt;- 0.18 * (1 - s^2.5) + 0.001\n  tube_radius[1:50] &lt;- sin(linspace(0, pi / 2, 50)) * tube_radius[50]\n \n  theta &lt;- linspace(0, 2 * pi * 4, points)\n \n  circle_theta &lt;- linspace(0, 2 * pi, circle_pts)\n \n  X &lt;- matrix(0, nrow = circle_pts, ncol = points)\n  Y &lt;- matrix(0, nrow = circle_pts, ncol = points)\n  Z &lt;- matrix(0, nrow = circle_pts, ncol = points)\n \n  for (i in 1:(points - 1)) {\n    R &lt;- path_radius[i]\n    center_x &lt;- R * cos(theta[i])\n    center_y &lt;- R * sin(theta[i])\n    center_z &lt;- z[i]\n \n    dx &lt;- path_radius[i + 1] * cos(theta[i + 1]) - center_x\n    dy &lt;- path_radius[i + 1] * sin(theta[i + 1]) - center_y\n    dz &lt;- z[i + 1] - center_z\n    tangent &lt;- normalize(c(dx, dy, dz))\n \n    ref &lt;- c(0, 0, 1)\n    if (abs(sum(ref * tangent)) &gt; 0.99) ref &lt;- c(1, 0, 0)\n \n    normal1 &lt;- normalize(cross3(tangent, ref))\n    normal2 &lt;- cross3(tangent, normal1)\n \n    r_tube &lt;- tube_radius[i]\n    for (j in 1:circle_pts) {\n      offset &lt;- r_tube * (cos(circle_theta[j]) * normal1 + sin(circle_theta[j]) * normal2)\n      X[j, i] &lt;- center_x + offset[1]\n      Y[j, i] &lt;- center_y + offset[2]\n      Z[j, i] &lt;- center_z + offset[3]\n    }\n  }\n \n  Z[, points] &lt;- Z[, points - 1]\n \n  list(X = X, Y = Y, Z = Z)\n}\n然后就是3D画图了：\nlibrary(rgl)\n \nxyz &lt;- shitshape()\n \nopen3d()\nbg3d(&quot;white&quot;)\nsurface3d(xyz$X, xyz$Y, xyz$Z, color = rgb(0.4, 0.2, 0), lit = TRUE)\naspect3d(1, 1, 1)\nlight3d(theta = -60, phi = 10)\nview3d(theta = -60, phi = 10)\n\n确实是比Python的好看。\n\n评论想看进阶版本，我翻一下，这不就是MATLAB的原创作者嘛，必须安排上。\n\n把他/她的MATLAB 版本给翻译成R，结构与参数基本一一对应，MATLAB我还是用过的，虽然经历比较短。\nlibrary(rgl)\n \nrot_x &lt;- function(theta) {\n  matrix(\n    c(\n      1, 0, 0,\n      0, cos(theta), -sin(theta),\n      0, sin(theta), cos(theta)\n    ),\n    nrow = 3,\n    byrow = TRUE\n  )\n}\n \nrot_y &lt;- function(theta) {\n  matrix(\n    c(\n      cos(theta), 0, -sin(theta),\n      0, 1, 0,\n      sin(theta), 0, cos(theta)\n    ),\n    nrow = 3,\n    byrow = TRUE\n  )\n}\n \nrot_z &lt;- function(theta) {\n  matrix(\n    c(\n      cos(theta), -sin(theta), 0,\n      sin(theta), cos(theta), 0,\n      0, 0, 1\n    ),\n    nrow = 3,\n    byrow = TRUE\n  )\n}\n \nrotate_xyz &lt;- function(X, Y, Z, R) {\n  pts &lt;- cbind(as.vector(X), as.vector(Y), as.vector(Z))\n  npts &lt;- pts %*% R\n  list(\n    X = matrix(npts[, 1], nrow = nrow(X), ncol = ncol(X)),\n    Y = matrix(npts[, 2], nrow = nrow(Y), ncol = ncol(Y)),\n    Z = matrix(npts[, 3], nrow = nrow(Z), ncol = ncol(Z))\n  )\n}\n \nrotate_xyz_col &lt;- function(X, Y, Z, R) {\n  pts &lt;- cbind(as.vector(X), as.vector(Y), as.vector(Z))\n  npts &lt;- t(R %*% t(pts))\n  list(\n    X = matrix(npts[, 1], nrow = nrow(X), ncol = ncol(X)),\n    Y = matrix(npts[, 2], nrow = nrow(Y), ncol = ncol(Y)),\n    Z = matrix(npts[, 3], nrow = nrow(Z), ncol = ncol(Z))\n  )\n}\n \nbezier_curve &lt;- function(ctrl, n = 50) {\n  t &lt;- seq(0, 1, length.out = n)\n  p &lt;- nrow(ctrl) - 1\n  basis &lt;- vapply(\n    0:p,\n    function(k) choose(p, k) * (t^k) * ((1 - t)^(p - k)),\n    numeric(length(t))\n  )\n  basis %*% ctrl\n}\n \ndraw_straw &lt;- function(X, Y, Z, color = rgb(88, 130, 126, maxColorValue = 255), lwd = 2) {\n  idx &lt;- which(Z == min(Z, na.rm = TRUE), arr.ind = TRUE)[1, ]\n  x1 &lt;- X[idx[1], idx[2]]\n  y1 &lt;- Y[idx[1], idx[2]]\n  z1 &lt;- Z[idx[1], idx[2]] + 0.03\n \n  ctrl &lt;- rbind(\n    c(x1, y1, z1),\n    c(0, 0, -0.7),\n    c((x1 * cos(pi / 3) - y1 * sin(pi / 3)) / 3, (y1 * cos(pi / 3) + x1 * sin(pi / 3)) / 3, -1.5)\n  )\n \n  p &lt;- bezier_curve(ctrl, n = 50)\n  lines3d(p[, 1], p[, 2], p[, 3], color = color, lwd = lwd)\n}\n \nset_color_by_h &lt;- function(H, c_list, n = 256) {\n  hmin &lt;- min(H, na.rm = TRUE)\n  hmax &lt;- max(H, na.rm = TRUE)\n \n  base_cols &lt;- grDevices::rgb(c_list[, 1], c_list[, 2], c_list[, 3])\n  pal &lt;- grDevices::colorRampPalette(base_cols)(n)\n \n  if (!is.finite(hmin) || !is.finite(hmax) || hmax &lt;= hmin) {\n    return(matrix(pal[n], nrow = nrow(H), ncol = ncol(H)))\n  }\n \n  x &lt;- (H - hmin) / (hmax - hmin)\n  idx &lt;- pmin(n, pmax(1, floor(x * (n - 1)) + 1))\n  matrix(pal[as.vector(idx)], nrow = nrow(H), ncol = ncol(H))\n}\n \nmake_waffle_cone &lt;- function(N = 500, n = 30) {\n  xs &lt;- seq(-1, 1, length.out = N)\n  ys &lt;- seq(-1, 1, length.out = N)\n  X &lt;- matrix(rep(xs, each = N), nrow = N, ncol = N)\n  Y &lt;- matrix(rep(ys, times = N), nrow = N, ncol = N)\n  Z &lt;- X * 0\n \n  for (k in 1:2) {\n    Z[seq(k, N, by = n), ] &lt;- 0.01\n    Z[, seq(k, N, by = n)] &lt;- 0.01\n  }\n \n  Z[X^2 + Y^2 &gt; 1] &lt;- NA_real_\n \n  R_x &lt;- rot_x(-pi / 2.9)\n  nXYZ &lt;- cbind(as.vector(X), as.vector(Y), as.vector(Z)) %*% R_x\n \n  nX &lt;- nXYZ[, 1]\n  nY &lt;- nXYZ[, 2]\n  nZ &lt;- nXYZ[, 3]\n \n  nZ &lt;- nZ - min(nZ, na.rm = TRUE)\n  nY &lt;- nY - min(nY, na.rm = TRUE)\n \n  denom &lt;- pmax(nZ / 2.5, 1e-6)\n  nT &lt;- nX / denom\n  nR &lt;- nY\n \n  nX2 &lt;- cos(nT) * nR\n  nY2 &lt;- sin(nT) * nR\n \n  list(\n    X = matrix(nX2, nrow = N, ncol = N),\n    Y = matrix(nY2, nrow = N, ncol = N),\n    Z = matrix(nZ, nrow = N, ncol = N)\n  )\n}\n \nmake_cylinder &lt;- function(radius = 0.04, segments = 100, height = 1) {\n  theta &lt;- seq(0, 2 * pi, length.out = segments + 1)\n  X &lt;- outer(cos(theta), c(radius, radius))\n  Y &lt;- outer(sin(theta), c(radius, radius))\n  Z &lt;- outer(rep(1, length(theta)), c(0, height))\n  list(X = X, Y = Y, Z = Z)\n}\n \npoop2 &lt;- function() {\n  open3d()\n  bg3d(&quot;white&quot;)\n  material3d(specular = &quot;black&quot;)\n \n  poop &lt;- shitshape()\n  surface3d(poop$X + 0.1, poop$Y, poop$Z + 1.06, color = rgb(0.4, 0.2, 0), lit = TRUE)\n  surface3d(poop$X / 1.3, poop$Y / 1.3, -poop$Z + 1.1, color = rgb(0.4, 0.2, 0), lit = TRUE)\n \n  cone &lt;- make_waffle_cone(N = 500, n = 30)\n  surface3d(cone$X, cone$Y, cone$Z, color = rgb(228, 200, 142, maxColorValue = 255), lit = TRUE)\n \n  cyl &lt;- make_cylinder(radius = 0.04, segments = 100, height = 1)\n \n  r1 &lt;- rotate_xyz(cyl$X, cyl$Y, cyl$Z, rot_x(pi / 5))\n  surface3d(r1$X, r1$Y, r1$Z + 1.3, color = rgb(0.8, 0.6, 0.4), lit = TRUE)\n \n  r2 &lt;- rotate_xyz(cyl$X, cyl$Y, cyl$Z, rot_x(pi / 6))\n  r2 &lt;- rotate_xyz(r2$X, r2$Y, r2$Z, rot_y(pi / 7))\n  surface3d(r2$X, r2$Y, r2$Z + 1.2, color = rgb(0.8, 0.6, 0.4), lit = TRUE)\n \n  aspect3d(1, 1, 1)\n  light3d(theta = -60, phi = 10)\n  view3d(theta = -60, phi = 10)\n}\n \npoop3 &lt;- function() {\n  open3d()\n  bg3d(&quot;white&quot;)\n  material3d(specular = &quot;black&quot;)\n \n  a &lt;- shitshape()\n  Xa &lt;- a$X\n  Ya &lt;- a$Y\n  Za &lt;- a$Z\n \n  rb &lt;- seq(0, 1, by = 0.01)\n  tb &lt;- seq(0, 2, length.out = 151)\n  f &lt;- (abs(1 - ((tb * 5) %% 2)) / 2) + 0.3\n  wb &lt;- outer(rb, f, &quot;*&quot;)\n \n  xb &lt;- wb * matrix(cos(pi * tb), nrow = length(rb), ncol = length(tb), byrow = TRUE)\n  yb &lt;- wb * matrix(sin(pi * tb), nrow = length(rb), ncol = length(tb), byrow = TRUE)\n  Zb &lt;- (-cos(pi * wb * 1.2) + 1)^0.2\n \n  color_list &lt;- rbind(\n    c(1.00, 0.92, 0.96),\n    c(1.00, 0.76, 0.90),\n    c(1.00, 0.60, 0.84),\n    c(0.98, 0.44, 0.76),\n    c(0.90, 0.26, 0.62),\n    c(0.78, 0.12, 0.48)\n  )\n \n  col_b &lt;- set_color_by_h(Zb, color_list)\n \n  yaw_z &lt;- 72 * pi / 180\n  roll_x_1 &lt;- pi / 8\n  roll_x_2 &lt;- pi / 9\n \n  R_z_2 &lt;- rot_z(yaw_z)\n  R_z_1 &lt;- rot_z(yaw_z / 2)\n  R_z_3 &lt;- rot_z(yaw_z / 3)\n  R_x_1 &lt;- rot_x(roll_x_1)\n  R_x_2 &lt;- rot_x(roll_x_2)\n \n  surface3d(Xa, Ya, Za + 0.7, color = rgb(0.4, 0.2, 0), lit = TRUE)\n \n  r &lt;- rotate_xyz_col(Xa, Ya, Za + 0.7, R_x_1)\n  r$Y &lt;- r$Y - 0.4\n  surface3d(r$X, r$Y, r$Z - 0.1, color = rgb(0.4, 0.2, 0), lit = TRUE)\n  draw_straw(r$X, r$Y, r$Z - 0.1)\n \n  for (k in 1:4) {\n    r &lt;- rotate_xyz_col(r$X, r$Y, r$Z, R_z_2)\n    surface3d(r$X, r$Y, r$Z - 0.1, color = rgb(0.4, 0.2, 0), lit = TRUE)\n    draw_straw(r$X, r$Y, r$Z - 0.1)\n  }\n \n  b &lt;- rotate_xyz_col(xb / 2.5, yb / 2.5, Zb / 2.5 + 0.32, R_x_2)\n  b$Y &lt;- b$Y - 1.35\n  for (k in 1:5) {\n    b &lt;- rotate_xyz_col(b$X, b$Y, b$Z, R_z_2)\n    surface3d(b$X, b$Y, b$Z, color = as.vector(col_b), lit = TRUE)\n    draw_straw(b$X, b$Y, b$Z)\n  }\n \n  b &lt;- rotate_xyz_col(xb / 2.5, yb / 2.5, Zb / 2.5 + 0.32, R_x_2)\n  b$Y &lt;- b$Y - 1.15\n  b &lt;- rotate_xyz_col(b$X, b$Y, b$Z, R_z_1)\n  for (k in 1:5) {\n    b &lt;- rotate_xyz_col(b$X, b$Y, b$Z, R_z_2)\n    surface3d(b$X, b$Y, b$Z, color = as.vector(col_b), lit = TRUE)\n    draw_straw(b$X, b$Y, b$Z)\n  }\n \n  b &lt;- rotate_xyz_col(xb / 2.5, yb / 2.5, Zb / 2.5 + 0.32, R_x_2)\n  b$Y &lt;- b$Y - 1.25\n  b &lt;- rotate_xyz_col(b$X, b$Y, b$Z, R_z_3)\n  for (k in 1:5) {\n    b &lt;- rotate_xyz_col(b$X, b$Y, b$Z, R_z_2)\n    surface3d(b$X, b$Y, b$Z, color = as.vector(col_b), lit = TRUE)\n    draw_straw(b$X, b$Y, b$Z)\n  }\n \n  b &lt;- rotate_xyz_col(xb / 2.5, yb / 2.5, Zb / 2.5 + 0.32, R_x_2)\n  b$Y &lt;- b$Y - 1.25\n  b &lt;- rotate_xyz_col(b$X, b$Y, b$Z, R_z_3)\n  b &lt;- rotate_xyz_col(b$X, b$Y, b$Z, R_z_3)\n  for (k in 1:5) {\n    b &lt;- rotate_xyz_col(b$X, b$Y, b$Z, R_z_2)\n    surface3d(b$X, b$Y, b$Z, color = as.vector(col_b), lit = TRUE)\n    draw_straw(b$X, b$Y, b$Z)\n  }\n \n  aspect3d(1, 1, 1)\n  light3d(theta = -15, phi = 35)\n  light3d(theta = 120, phi = 20)\n  view3d(theta = -15, phi = 35)\n}\n我把shit这个词改成用poop，毕竟shit是脏话，poop就不是了，是幼儿友好的，等同于中文的粑粑。\n我们只要运行一个poop2()就可以出来巧克力味的冰激凌了，还带两饼干🍪：\n\n然后运行poop3()，就能够得到花朵簇拥的一堆粑粑：\n\n参考资料\n\nMATLAB | 这是屎吗？抱歉打错了，这是什么？ - 知乎\nMATLAB在逐渐被Python淘汰吗？ - 知乎\n"},"文章发表/文章发表：aplot让你轻松画出复杂的图":{"slug":"文章发表/文章发表：aplot让你轻松画出复杂的图","filePath":"文章发表/文章发表：aplot让你轻松画出复杂的图.md","title":"aplot让你轻松画出复杂的图","links":[],"tags":["aplot","paper","visualization"],"content":"aplot发表\naplot包发表在The Innovation期刊上。\n\n开发这个包的灵感来自于我在2018年发的MBE文章。\n\n可以说这是对数据整合和可视化长期思考所得，进行高度抽象才提出这两个方法，而这两个方法，分别激发了我开发出来aplot和ggtangle两个包。\n复杂图不再复杂\naplot作为一个拼图包，和大家所熟知的拼图包cowplot和patchwork是不一样的。不是把图放在一起，而是把图中的数据进行关联，就像文章图2所展示，你画几个图，无需知道数据间的关系，每个图画起来都比较简单，但是你一旦用aplot的insert_top、insert_bottom、insert_left和insert_right系列函数进行拼图，这些函数会试图去把数据给关联起来，对每个小图的内容进行重新排列，以使得图与图之间信息是对应的。最终出来底下G图这样复杂的图，如果要手搓这个图，难度很大，用aplot，很简单。\n\n这个包的重点，就是这个功能，是我开发它的初衷。期间还有点小插曲，写个包总有人想抄代码。借此分享这段tweet给大家。\n\n你也能创作复杂图\n能够拼的图种类是比较多的：\n\n当然你也可以自己创作一些，因为怎么拼随便你嘛。比如前面图2的单细胞marker基因表达热图，我就拼了通路富集分析结果。比如这里的A图中，oncoplot就被拿来再拼TCGA中相应基因在两个肿瘤中表达量分布。再比如E图，upsetplot我们可以用aplot拼出来，但既然是拼的，我干嘛不拼点别的呢？于是我们就搞了这个不一样的upsetplot。\n说到oncoplot，是由一个学生李申锁贡献的代码，详见《ggplot2版本的oncoplot来了》，在我面前露一手，然后跟我说要申请博士，但由于我没有名额，然后也就没有然后了。虽然接触时间短，也过了比较长一段时间，但贡献我是不会忘记的。\n\n普通的拼图\naplot另外的功能是plot_list()，就是普通的拼图的，图不会变，只是简单地组合起来放在一起。虽然patchwork包做得很好，但我是老狗学不了新把戏，早期用惯了cowplot::plot_grid，我就想来一个类似的，当然也不完全一样，我还是有我自己的一点东西在里面。\n\n啥都能拼：base plot、ggplot2、图片等\n\n\n\n\n万物皆可分面：这些拼在一起的图，只要你给个名字，就会变成像分面的label一样，在出图时呈现。\n\n\n保持YuLab团队的五毛效果：我们开发一些包，比如说ggbreak，它所呈现的效果，你用其它的拼图工具，可能就不兼容了，但我们自己，自成一统。配合得舒舒服服的。\n\n\nGA图创作\n\n最后讲讲这张GA图，一开始画了一版，呈现4个函数的功能，我觉得（1）和图一太重复；（2）这4个函数是可以自由组合，反复使用的，这点体现不出来。所以我提了意见，用一条彩带，后面虚化，代表未完待续，还能继续调用这些函数**。**然后可以把aplot拟人化，成为舞动彩带者。至于上面拼图的元素，我的想法是哆啦A梦的口袋，后面双斌提出来说感觉口袋是aplot这个人的，换成云。一开始设计师就在云上面平铺了几个图，我觉得不行，跟设计师说，想想天兵天将要捉拿孙悟空的场景，图要堆不同的层，后面可以虚化一些，体现人多势众的感觉。就这样出来我们这张GA图。\n我是第一人\n\naplot的灵感来自于2018年我的文章，在ggtree中孕育了好几年。然后我在2020年就开发出来并放出到CRAN上。解决我前面小标题写的复杂图不再复杂这个问题，aplot必须是第一个工具。现在有类似的工具，包括python的Marsilea和R的ggalign。第一个是最难的，因为你要产生想法，要在没有任何借鉴的情况下去实现。现在aplot的功能可能不是最全的，但aplot肯定是最容易用的，能解决你大多数的问题。"},"文章发表/文章发表：两测序平台在单细胞空间转录组研究中的比较":{"slug":"文章发表/文章发表：两测序平台在单细胞空间转录组研究中的比较","filePath":"文章发表/文章发表：两测序平台在单细胞空间转录组研究中的比较.md","title":"综述解析空间转录组技术在神经科学中的应用","links":[],"tags":["benchmark","paper","single-cell","spatial-transcriptomics"],"content":"\n国产平台替代国外平台是趋势，但“能不能用”“用起来怎么样”，终归要靠数据说话。我们做了一次对比：在单细胞空间转录组（单细胞级别的空间信息）场景里，把 GeneMind SURFSeq 5000 和 Illumina NovaSeq 6000 放在同一套流程、同一类样本上跑一遍，看看差异到底在哪里。\n这次用到的空间转录组技术是寻因的 SeekSpace。它和很多“在切片上原位测序”的路线不太一样：传统思路大多是把转录本透化下来、留在组织原位做检测；SeekSpace 的做法更像“把空间坐标带进细胞里”，再去做单细胞测序。\n简单说就是：\n\n数据形态上，它仍然是一份单细胞转录组数据；\n但每个细胞额外带着“位置探针”，所以你能把细胞放回空间里。\n\n这种路线当然不是唯一解，但就商业化产品而言，目前寻因是比较有代表性的。我们也想做点不一样的：和寻因合作，在 SeekSpace 的体系下完成测序和对比。\n我们做了什么\n样本包括小鼠脑和肺组织。对比不只看“能出多少 reads/UMI”这种产出指标，也看一整套下游分析能不能得到一致结论，包括：\n\n\n降维与聚类\n\n\n细胞类型注释\n\n\n空间定位\n\n\n差异表达基因\n\n\n通路分析\n\n\n细胞间通讯\n\n\n空间热点模块检测（这一块用的是我们课题组自主研发的 SVP 工具）\n\n\n结果如何\n整体一致性很好：\n\n一个梦想\n最后想说一点“技术之外”的感受：现在很多语境里，国产被夸时常常是“便宜平替”。但我更希望有一天，我们谈起国产时，关键词会变成“卓越独特”。\n我让 DeepSeek 模仿《I have a dream》的风格，用更有节奏感的方式表达这个愿望。是的，我有一个梦想：\nI have a dream that one day, our homegrown platforms will no longer be seen as mere affordable substitutes, but as superior choices celebrated for their unique brilliance.\nI have a dream that one day, the world will choose “Made in China” not because it is economical, but because it offers unmatched features and unparalleled innovation — because it is genuinely better."},"文章发表/文章发表：使用treeio和ggtree探索Phylogenetic-placement数据":{"slug":"文章发表/文章发表：使用treeio和ggtree探索Phylogenetic-placement数据","filePath":"文章发表/文章发表：使用treeio和ggtree探索Phylogenetic placement数据.md","title":"使用treeio和ggtree探索Phylogenetic placement数据","links":[],"tags":["treeio","ggtree","placement","paper"],"content":"要想了解这篇文章，必须读一读我在《文章发表：TIPars快速更新树以应对不断增加的基因组数据》写的，当时读博的时候，用JAVA开发TIPars。题外话，作为学生，我一点都不挑活，来啥都是盘它，当时我是真的从图书馆借了几本JAVA的书开始的。\nTIPars干的事情就是placement，那时候有pplacer和EPA两个软件，EPA其实不是一个独立软件，是RAxML里的一个功能，后来COVID来了，又有几个软件出来。但是当时是一个很小众的东西。\n我博士期间还写了ggtree全家桶，我既然做phylogenetic placement，那当然少不了ggtree的支持了。解析文件，信息整合可视化，这些是少不了的。在2017年发表的ggtree文章（2015年投稿，2016年上线），它已经就有了。\n\n只不过是后来解析文件分离成treeio（我又加了很多文件输出功能，所以是io），ggtree负责可视化，当然还有数据操作tidytree包。而ggtree系列中placement的功能，一直以来都可以说是独步江湖，可能也是因为太小众了，解析数据进行可视化，非常缺，只有少量工具能做简单的可视化。\nggtree的功能太多，我要写ggtree的话，placement的支持也只是一小段稍带过而已，而这又是一个相对比较独立的功能，所以我一直是有个想法，单独把这块拎出来写个小文章。搞一点case studies，然后把这个功能好好地说一说，比较完整全面地跟大家介绍一下。\n\n文章中的例子其实我不是很满意，因为只有placement的数据，而ggtree擅长数据整合，特别是现在有ggtreeExtra，《文章发表：ggtreeExtra — MBE》，我希望能够整合一点别的数据，通过其它的Phylogenetic data和placement data进行整合能够带来新的insights，我希望能有这样一个case study。所以不单单是placement我有很好的支持，在ggtree这样的框架下，是有加持的。但是学生跟我说，找不到相应的数据。\n不管怎么说，treeio + ggtree这样的组合之下，能够帮助我们对placement数据进行探索与可视化。我们提供了一个比较好的解决方案。\n\nM Chen#, X Luo#, S Xu#, L Li, J Li, Z Xie, Q Wang, Y Liao, B Liu, W Liang, K Mo, Q Song, X Chen*, TTY Lam*, G Yu*. Scalable method for exploring phylogenetic placement uncertainty with custom visualizations using treeio and ggtree. iMeta. 2025, 4(1):e269.\n"},"文章发表/文章发表：功能富集分析的背景偏差":{"slug":"文章发表/文章发表：功能富集分析的背景偏差","filePath":"文章发表/文章发表：功能富集分析的背景偏差.md","title":"功能富集分析的背景偏差","links":[],"tags":["clusterProfiler","ORA","paper"],"content":"\n你可能遇到过这种“怪事”：\n\n同一份基因列表，别的工具能跑出一堆显著通路，clusterProfiler 却结果很少，甚至没有。\n同一条通路，别的工具给出的 p 值小很多，看起来“更显著”。\n\n这两件事，其实是一回事：很多时候，不是 clusterProfiler “不灵”，而是它把容易踩坑的细节都算进去了，所以 p 值更保守、结果更克制。经过多年不懈努力地说，大家慢慢形成了共识：富集分析要避坑，clusterProfiler 值得优先考虑。\n\n我的❤️充满惆怅，只为今天的村庄还唱着过去的歌谣\n\n富集分析离不开基因功能注释库。Nature Methods 的文章提到：有超过 42% 的软件，注释库几年都不更新。你拿着今天的数据，却用几年前的注释去解释它，就像“带着现在的问题，穿越回过去找答案”。就连SCIENCE文章都会被吐槽，这件事大家已经开始重视。\n\n臣妾要告发 熹贵妃私通 结果不显著，秽乱后宫 定是分析有误，罪不容诛！\n\n但还有一个更容易“把人哄开心”、却更危险的坑：背景偏差。\n注释库老旧之所以容易被注意，是因为它会让显著结果变少；而背景偏差之所以容易被忽略，是因为它往往让显著结果变多、p 值变得更小，看起来更漂亮。\n有时我们不是不关心真相，而是默认了一个心态：只要 p 值小，里面有我想看到的通路，就算“过关”。更糟的是，有些工具甚至不允许你指定背景基因，或者背景来源含糊不清。结果就像早期搜索引擎那样：搜不到也得给点东西，让用户觉得“这工具真行”。\n你可能也听过“背景很重要”，但现实里，很多人并不会把背景当回事：反正结果能显著就行。问题是：背景一旦选错，显著不一定代表真相，更可能代表“统计游戏玩对了”。\n先把概念说清楚：\n\nGSEA 通常不需要你显式指定背景基因集合。\nORA（过表达富集）本质上是一个无放回抽样的统计过程，背景非常重要：你根本检测不到/定量不到的基因，就不可能在抽样里被抽中，也就不应该出现在背景里。\n\n背景问题并不新。我读研时做 microarray 分析就知道它的重要性，只是很多年里一直没被足够重视。这篇文章也不是为了重复“背景要对”这个老话，而是想强调一个更隐蔽、但影响很大的细节：\n在 clusterProfiler 的 ORA 里，我会把没有注释的基因扔掉。\n原因是：在 ORA 里，我们把基因分成“属于该通路 / 不属于该通路”。可没有注释的基因其实是未知。如果你不把它们扔掉，它们常常会被默认归到“不属于”，这会引入另一层偏差，让 p 值更容易变小。\n据我所知，只有 clusterProfiler 坚持这么做，也因此经常被质疑：“别人都没这么搞。”这篇文章就是在讲清楚：我为什么这么做，以及你为什么最好也这么做。\n另一个常见误区是：直接拿全基因组当背景。\n这个想法在 microarray 时代就存在，但今天它带来的偏差反而更容易被放大：非编码基因越来越多，而这些基因通常缺乏功能注释；同时，在转录组/蛋白组实验里，它们又往往不可能被鉴定或定量。很多工具如果把“所有基因 ID”都塞进背景里，背景里就会混入大量“理论上存在、实际不可能抽到”的基因，p 值就更容易被压得很小很小。\n而 clusterProfiler 做“背景基因 ∩ 注释库”的交集处理，并把没有注释的扔掉，恰好会滤掉一大批缺乏注释的基因（其中相当一部分是非编码基因）。所以即使你懒到用全基因组当背景，结果也不至于偏得太离谱；而当你认真指定了更合理的背景时，这个处理会让 p 值更可靠、更保守。\n\n所以这篇文章想强调的核心只有一句话：\n背景基因要和注释库取交集，这是 clusterProfiler 的做法，你最好也这么做。\n\n\n使用全基因组做背景，用这一招，让懒人不犯大错，这一操作影响是比较大的。\n\n\n当我们有意识地去指定一个正确的背景，用这一招，让 p 值更准确保守一点，影响比较小。\n\n\n如果你只想带走一个“能立刻用起来”的操作建议：\n\n做 ORA 时，背景尽量用“实验里有机会被检测/定量到的基因集合”，别图省事直接上全基因组。\n无论背景怎么选，都把背景和注释库取交集，再做富集；把没有注释的基因当作“未知”，不要硬塞进“不属于”。\n报告里写清楚你用的注释库版本和背景定义，这比多几个显著通路更有说服力。\n\n作为一篇 Editorial，我也想呼吁期刊、审稿人、工具开发者和研究者：把背景偏差当成必须认真对待的问题。富集分析的价值是帮助我们接近机制，而不是帮助我们把 p 值“做得更好看”。"},"文章发表/文章发表：小丫画图，代码开放，注释中英文对照":{"slug":"文章发表/文章发表：小丫画图，代码开放，注释中英文对照","filePath":"文章发表/文章发表：小丫画图，代码开放，注释中英文对照.md","title":"小丫画图，代码开放，注释中英文对照","links":[],"tags":["FigureYa","paper","visualization"],"content":"\n作为_iMetaMed第一卷第一期的封面文章发表，也就是说创刊号的封面文章，说起来好像蛮有纪念意义一样。特别是如果iMetaMed_能够成为一个高攀不起的期刊的话。\n\n文章的解读可以参考：《iMetaMed | 大连医科大学葛瑛-FigureYa：一个用于提升生物医学数据解读与研究效率的标准化可视化框架》，还有从小丫个人角度的版本：《FigureYa更新啦！借助学术的力量》。\n\n这个评论谬赞了，但对于小丫画图来说，真的就是这个味。当年我博士还没毕业的时候，小丫说想要搞个众筹模式，来帮助大家实现下游的一些数据可视化需求，问我能不能来支持一下。我大概说我可以先来打个样，记得小丫说有我的支持，她有信心可以搞起来。印象中大概我还有写过一句lapply()出几个boxplot，然后对接cowplot::plot_grid，直接出一张图的代码。然后果子大加称赞，觉得不看我代码，只会for循环。近十年了，应该没记错，还没老年痴呆。\n\n今时今日的你可能无法想象画一个箱线图都会有困难，但事实就是小丫画图帮助了无数的研究生，后来各种各样的画图云平台，我们其实也可以看到不少小丫画图的身影。至于说“AI时代了，画图有何难，AI帮你写代码”，那AI的知识库也是无数的文档、教程、博客、论坛问题等等，是无数具有互联网分享精神的网友们打下的基础，让我们用上面这一页PPT致敬一下那个时代。\n后面我基本不去写，但有介绍学生去接活，也有给一些人指导，属于偶尔幕后一下。其中，有一个代码，我指导他打成R包，后面还拿去发了一篇小文章，现在也是一篇ESI高被引论文。\n\n这个事情应该说，帮助了很多学生，想要实现的图搞不出来，提出需求，众筹成功了，就能拿到带有示例数据、中文注释、能跑通的代码。如果要画的图，是现有的，就直接付费。一杯奶茶的费用，可以说毫无负担。随着时间的推移，积累的图越来越多，有317个。毫无疑问，对广大研究生的课题推进，是有帮助的。\n其实我想强调的是，花一杯奶茶的钱，不单单是要把图画出来，这是赶工着急的时候干的事，只想要结果。我们还应该在有闲的时候，回过头来看这个代码。这是一个学习的过程，这杯奶茶钱就花得太值。当然现在文章发表了，代码开放了，还重新整理，加了中英文注释。不单单是免费的工具，再次强调一下，也是一个很好的学习资源。不知道为什么，这年代叫人学习，天打雷劈。"},"文章发表/文章发表：综述解析空间转录组技术在神经科学中的应用":{"slug":"文章发表/文章发表：综述解析空间转录组技术在神经科学中的应用","filePath":"文章发表/文章发表：综述解析空间转录组技术在神经科学中的应用.md","title":"综述解析空间转录组技术在神经科学中的应用","links":[],"tags":["spatial-transcriptomics","paper","review","neuronscience"],"content":"2024年1月份，我们在The Innovation期刊上发表过一篇评述，《文章发表：脑细胞图谱 - 开启神经科学新时代》，主要针对当时在CNS上发表的脑细胞图谱资源进行评述，这些研究为我们深入了解不同物种大脑细胞组织和空间分布、解密大脑提供新的视角。\n同年我们又在The Innovation Life上发表了一篇空间转录组的大综述，《文章发表：空间转录组学 - 在多种应用中对跨组织和器官结构的基因转录的计算性见解》，正如标题所写，这篇综述着重在计算性见解，我们对数据分析进行较为系统的综述，对大家分析空间转录组数据是有参考价值的，其次就是在应用层面，包括器官发育、病理过程、肿瘤、脑科学、药物研发等多个方面。\n这篇文章发表在Small Methods期刊，《【揭秘脑空间基因密码】南方医科大学余光创团队SMTD：综述解析空间转录组技术突破及其在神经科学的应用》，收录在Small Methods特辑：单细胞与空间转录组学解析组织复杂性。\n这个工作，入选《Small Methods》的卷首插图文章。\n\n技术进展\n我们首先在技术创新的层面上，梳理了空间转录组技术的发展路径，包括基于成像的技术路线和基于测序的技术路线。\n\n这张图用了我们团队开发的ggbreak和shadowtext两个包来画。\n\n\nggbreak：你们要的坐标轴截断，它来了\n\n\n文章发表：ggbreak让你更好地利用画图空间\n\n\n带你装逼带你飞，画图的文本打出阴影立体效果\n\n\n计算工具\n阐述了上游预处理，包括组织切片配准和空间坐标校准。下游数据分析，包括细胞类型注释、空间高可变基因识别、细胞通讯以及多切片数据融合等核心算法。这样上下游整个计算分析就比较完整地综述。\n\n\n脑科学应用\n综述了三个方面：\n\n\n不同的物种的全脑分子图谱\n\n\n多物种的脑发育轨迹\n\n\n多脑区疾病研究\n\n\n\n\n论文信息\n\nQ Wang, H Zhu, L Deng, S Xu, W Xie, M Li, R Wang, L Tie, L Zhan, G Yu*. Spatial Transcriptomics: Biotechnologies, Computational Tools, and Neuroscience Applications. Small Methods. 2025, 9(5):2401107.\n"},"机器学习与统计方法/AI学起来，毕竟AI让地球运转":{"slug":"机器学习与统计方法/AI学起来，毕竟AI让地球运转","filePath":"机器学习与统计方法/AI学起来，毕竟AI让地球运转.md","title":"AI学起来，毕竟AI让地球运转","links":[],"tags":["DeepLearning"],"content":"Andrew Ng在搞Coursera之前，有个OpenClass，就是教Machine Learning，那是远在2010年，非常久远，但是可以说，后面的那些课程，都是在那个基础上弄的。其实差不多，另一方面就是那个年代久远，Python根本不像现在这样流行，那个年代还整天在Perl VS Python，而不是今天的R VS Python。然后这个OpenClass的课程，是用Matlab/Octave教的，我印象中应该是Matlab，然后课程作业我是用Octave作的。然后我又自己用R重新写了，打了一个R包，取名mlass是ML + clAss的意思，无意中变成了ML + ass。\n\n我大概实现了大部分基础的东西，神经网络没有写。\n\nLinear Regression with one variable &lt;2012-01-06, Fri&gt;\nLinear Regression with multiple variables &lt;2012-06-28, Thu&gt;\nLogistic Regression &lt;2012-06-20, Wed&gt;\nRegularization for preventing overfitting &lt;2012-06-27, Wed&gt;\nNeural Networks\nSupport Vector Machines &lt;2012-04-11, Wed&gt;\nHierarchical clustering, single and complete method &lt;2012-12-10, Mon&gt;\nHierarchical clustering, average (UPGMA) method &lt;2014-08-22, Fri&gt;\nK-Means algorithm &lt;2011-12-30, Fri&gt;\nPrincipal Component Analysis\n\n但是这个十几年前写的包，还是挺好的，因为除了实现算法之外，结果用S4对象存，写了方法访问数据，写了可视化代码画图，然后部分计算的东西，我还用C++写了。当年的session info，ggplot2还是0.9.0，非常古早。\n\n所谓人丑要多读书，AI得继续学起来，于是翻出来这个旧代码，发现这个包安装报错了，修正了一下。文档也从原来用LaTeX写的，换成了用Markdown来写。它又可以安装了。\n例子大概比如kmeans里迭代中心点，画出来这样子：\n\n再比如一个SVM分类的例子，结果是这样子：\n\n前两年大家还在说大数据就像少年性事，大家都在讲但没人做过。现在AI都快成为大学生的通识课了。必须要搞起来。"},"机器学习与统计方法/KMeans应用于非线性数据":{"slug":"机器学习与统计方法/KMeans应用于非线性数据","filePath":"机器学习与统计方法/KMeans应用于非线性数据.md","title":"KMeans应用于非线性数据","links":[],"tags":["MachineLearning","KMeans","Classification"],"content":"书接上一回，对于线性不可分的数据，怎么用KMeans来做聚类。\n数据\n用make_moons来生成一个比较复杂的流形数据。\nfrom sklearn.datasets import make_moons\n \nX, y = make_moons(200, noise=0.05, random_state=0)\n画图看一下，数据是长这样子的：\nimport matplotlib.pyplot as plt\n \nplt.scatter(X[:, 0], X[:, 1], s=50, c=y, cmap=&#039;viridis&#039;)\n\n简单的KMeans是分不好的\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2)\nlabels = kmeans.fit_predict(X)\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap=&#039;viridis&#039;)\n我们用KMeans来聚类，然后用聚类结果进行上色：\n\n效果只能说不行。\nt-SNE + KMeans\n做过单细胞分析的，都知道t-SNE，当然你也可以试试UMAP，效果应该差不多。t-SNE擅长捕捉局部结构，就特别适合这种流形数据。它在高维空间用高斯分布计算样本间的相似度，然后用t分布匹配高维概率分布，通过梯度下降优化低维嵌入，优化目标是最小化高维和低维概率分布的KL散度。\n我们对数据先进行标准化：\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n再进行t-SNE的变换：\nfrom sklearn.manifold import TSNE\n \n \nX_tsne = TSNE(n_components=2, perplexity=30, random_state=42).fit_transform(X_scaled)\ny_tsne_kmeans = KMeans(n_clusters=2).fit_predict(X_tsne)\n这时候，我们可以对变换后的数据进行可视化：\nplt.scatter(X_tsne[:,0], X_tsne[:,1], c=y, cmap=&#039;viridis&#039;, s=50)\n\n非常好地保留了原来的分类信息，然后这个数据就成了线性可分了。\n那么我们可以可视化原始的数据，并用KMeans聚类结果进行上色，看看聚类效果如何：\nplt.scatter(X[:, 0], X[:, 1], c=y_tsne_kmeans, s=50, cmap=&#039;viridis&#039;)\n\n谱聚类\n谱聚类本质上就是核KMeans的优化版本，就是上次说的应用核函数再加KMeans，当然如果你自己这么简单做了，效果可能不太好，因为谱聚类做得更多，所以更加鲁棒。它先计算一个相似度矩阵（可以通过高斯核函数+欧式距离，也可以通过KNN连接矩阵），再构建拉普拉斯矩阵对相似度矩阵进行归一化，再计算特征向量（本质就是低维嵌入），然后对特征向量运行KMeans。\nfrom sklearn.cluster import KMeans, SpectralClustering\nspectral = SpectralClustering(n_clusters=2, \n                             affinity=&#039;rbf&#039;,\n                             gamma=15,\n                             random_state=42)\ny_spectral = spectral.fit_predict(X_scaled)\nplt.scatter(X[:, 0], X[:, 1], c=y_spectral, s=50, cmap=&#039;viridis&#039;)\n这里我就用了affinity=&#039;rbf&#039;也就是高斯核函数，gamma这个参数控制高斯核函数的宽度，数据复杂的情况下，gamma就可以调大一点试试。最后的聚类结果效果就非常好。\n"},"机器学习与统计方法/深度学习/PyTorch对数据进行多分类":{"slug":"机器学习与统计方法/深度学习/PyTorch对数据进行多分类","filePath":"机器学习与统计方法/深度学习/PyTorch对数据进行多分类.md","title":"PyTorch对数据进行多分类","links":[],"tags":["DeepLearning","Pytorch","Classification"],"content":"书接上一回，从二分类往前走两步，这次来做多分类。\n数据\nimport numpy as np\nimport matplotlib.pyplot as plt\nRANDOM_SEED = 42\n \nnp.random.seed(RANDOM_SEED)\n \nN = 100\nD = 2\nK = 3\n \nX = np.zeros((N*K, D))\ny = np.zeros(N*K, dtype=&#039;uint8&#039;)\n \nfor j in range(K):\n    ix = range(N*j, N*(j+1))\n    r = np.linspace(0.0, 1, N)\n    t = np.linspace(j*4, (j+1)*4, N) + np.random.randn(N) * 0.2\n    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n    y[ix] = j\n生成个三分类的数据来训练模型，对于模型来说，多少个分类都是一样训的。\n数据大概是长这样子的：\n\n数据现在是numpy，要转成tensor，然后要放到合适的device（放到GPU去），然后还要切分数据为训练集和测试集。\nimport torch\nX = torch.from_numpy(X).type(torch.float)\ny = torch.from_numpy(y).type(torch.LongTensor)\n \nX = X.to(device)\ny = y.to(device)\n \nfrom sklearn.model_selection import train_test_split\n \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n模型\nfrom torch import nn\n \nClassification = nn.Sequential(\n    nn.Linear(in_features = 2, out_features = 10),\n    nn.ReLU(),\n    nn.Linear(in_features = 10, out_features = 10),\n    nn.ReLU(),\n    nn.Linear(in_features = 10, out_features = 3)\n).to(device)\n这和我们上次做二分类有什么区别，可以说根本没区别，当然如果你仔细看的话，原来二分类的输出是一个logit，然后我们过一个sigmoid，出来分类的概率。这里是多分类，对每一个分类都会有一个logit，所以输出的长度与分类的数目一致，这里是3分类，就设定out_features = 3。这长度为3的logits，依然需要有一个函数给转成这三种分类的概率，这就需要用softmax函数。预测的结果就是概率最大的分类。\n\n损失函数\nloss_fn = nn.CrossEntropyLoss()\n正如我们在二分类里介绍的，分类用交叉熵来计算损失，这里相应地就用了nn.CrossEntropyLoss()函数。\n优化器\noptimizer = torch.optim.Adam(params = Classification.parameters(), lr = 0.01)\n\n上次我们用随机梯度下降（SGD），这次我们换一个，用Adam，Adam这个方法的基本思路是融合了两种方法：Momentum和AdaGrad。Momentum参照小球在碗中滚动的物理规则进行移动；AdaGrad会记录过去所有梯度的平方和，学习越深入，更新的幅度就越小。Adam通过组合这两个方法的优点，有望实现参数空间的高效搜索。\n准确率\nfrom torchmetrics import Accuracy\n \nacc_fn = Accuracy(task=&quot;multiclass&quot;, num_classes = K).to(device)\nacc_fn\n准确率这个函数和我们做二分类基本一样，差别就在于指定了不同的num_classes参数而已。\n训练模型\nfrom timeit import default_timer as timer \n \nstart_time = timer()\n \nepochs = 1000\n \nfor epoch in range(epochs):\n    ## Training\n    Classification.train()\n \n    y_logits = Classification(X_train)\n    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n \n    loss = loss_fn(y_logits, y_train)\n    acc = acc_fn(y_pred, y_train)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n \n    ## Testing\n    Classification.eval()\n    with torch.inference_mode():\n        test_logits = Classification(X_test)\n        test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n        test_loss = loss_fn(test_logits, y_test)\n        test_acc = acc_fn(test_pred, y_test)\n \n    if epoch % 100 == 0:\n        print(f&quot;Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}&quot;)\n \nend_time = timer()\n和二分类的训练代码基本上是一样的，就是把模型一换，把logits要过一下sigmoid换成softmax而已。\n\n也是很快就收敛了，准确率很高，用时5秒不到。\n\n可视化\n最后我们把模型在训练集和测试集的决策边界给画一下：\n"},"机器学习与统计方法/深度学习/卷积神经网络CNN":{"slug":"机器学习与统计方法/深度学习/卷积神经网络CNN","filePath":"机器学习与统计方法/深度学习/卷积神经网络CNN.md","title":"卷积神经网络CNN","links":[],"tags":["DeepLearning","CNN","Pytorch","Classification"],"content":"数字识别用传统的机器学习就可以做到蛮高的准确率，使用神经网络，完全也可以用全连接的网络来识别，无非是一个多分类的问题。和我们平时做多分类没有差别。这里我们用卷积神经网络（CNN）来做，CNN在图像识别上应用非常广泛。因为全连接神经网络的输入是一个向量，把图片按照行连接成一个向量，就会把空间信息给抹掉。这就是CNN要解决的，要利用空间信息，来找patterns，比如要识别一只鸟，图片中有一小块是一个鸟嘴，这对识别鸟是有用的。\nCNN概述\nCNN和全连接的神经网络的区别首先在在于它传递的数据是有形状的，也就是前面说的要利用空间信息，所以用sliding windows的策略，扫描一个又一个的窗口（patches），这个窗口每次扫描就用一个滤波器（filter）去做inner product，一个窗口出来是一个值。\n\n这一个滤波器作用于这一个通道上，会出来另一个大小不一样的二维数据，所以输入输出有时候又可以统一称之为特征图。输入通常不是一个通道，比如说RGB的图，就有RGB三个通道，最终的输出是每一个通道都一样的做法，然后将多个通道进行加和。\n\n滤波器主要用于提取图像的特征，比如下面这张图所演示的。\n\n一个滤波器出来一张特征图，多个滤波器就会出来多个特征图，就像RGB的图有三个通道一样，用N个滤波器，出来的数据就有N个通道，每个通道是2D的数据，整个是一个3D的数据，我们依然可以理解成一张图，原来的图是3个通道，现在有N个通道了，不是我们理解的RGB图像，但形式上是一致的。这就是卷积的过程。\n\n滤波器里的数值，相当于我们在全连接神经网络中权重，也会加上偏置，这些参数都是学习出来的。\n\n一个典型的卷积神经网络就是卷积→激活→池化，可以是一个这样的过程，也可以连着搭几个。这个做为Feature learning，把图像的特征学出来，然后用这些特征做为输入，接一个全连接的神经网络（也被称之为dense network），这就是完整的CNN。\n卷积层\n\n运算就是前面讲到的相当于图像处理的滤波器运算。这里涉及到一些和运算细则有关的概念，包括kernel size, padding和stride，这些会影响到输出的数据形状大小，这也要算一下的，因为最终要过一下全连接层，输入的大小是要准确指定的。\n滤波器（filter/kernel）\n滤波器有时候也叫kernel，因为滤波器是不需要我们指定的，也是学出来的，我们要指定的只有滤波器的数量，也是输出的channel数目，还有滤波器的大小，kernel size。\n填充（padding）\n一个4x4的数据，用一个3x3的滤波器，输出的数据就变成了2x2，所以这样子，如果叠加卷积层，就有可能在中间变成1x1，后面没法再继续做卷积了。所以就需要在数据的边缘进行填充，像下面这个例子，通过填充就可以让输入和输出保持4x4的形状。\n\n步幅（stride）\n在应用滤波器时，通过移动窗口，把所有的数据都过一遍，窗口和窗口之间是有重叠的，移动窗口的步伐有多大，就是步幅。\n\n池化\n典型的CNN包括卷积→激活→池化，激活就是ReLU这些，都很清楚，最后就池化：\n\n池化没有需要学习的参数，就是在目标区域里取个代表性的值，上图是最大值，也可以是平均值。池化是在每个通道单独进行，所以不会改变通道数。\n输入数据发生一点微小的变化，通过池化，输出基本上是不变的，这样就具有一定的鲁棒性。当然其实池化最主要的作用是让数据变小，这本身是为了更高效的计算。从这个角度来说，计算资源够的情况下，是可以不需要池化的。\n书上讲的都是说让数据变小这一点，我自己想到的是，因为卷积运算可以套好几个，那么经过池化之后，再做同样大小的滤波运算，相当于在更大的区域去捕获特征了。我认为是有这个作用的，相当于前面是低空看细节，后面高空看轮廓，有这样一个过程的作用。\n另外也要看实际情况，对于一般的图像处理来说，池化的过程，相当于压缩了图片，压缩完图片看着变化不大。AlphaGO就使用了CNN，但是它就没有用池化，因为池化了之后，棋盘就不完整了，这和图像处理是有区别的，所以它不能够用池化。所以说，还得具体情况具体分析。\nPyTorch实战\n数据\n这里使用的是MNIST手写数字的数据集，有6万张图片。先创建文件夹，然后下载，如果文件已经存在，就跳过下载。\nfrom pathlib import Path\nimport requests\n \nDATA_PATH = Path(&quot;data&quot;)\nPATH = DATA_PATH / &quot;mnist&quot;\n \nPATH.mkdir(parents=True, exist_ok=True)\n \nURL = &quot;github.com/pytorch/tutorials/raw/main/_static/&quot;\nFILENAME = &quot;mnist.pkl.gz&quot;\n \nif not (PATH / FILENAME).exists():\n    content = requests.get(URL + FILENAME).content\n    (PATH / FILENAME).open(&quot;wb&quot;).write(content)\n这个数据是个pickle文件，存的是numpy array格式，我们相应地把它解压缩，讲进来。\nimport pickle\nimport gzip\n \nwith gzip.open((PATH / FILENAME).as_posix(), &quot;rb&quot;) as f:\n    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=&quot;latin-1&quot;)\n总共有6万张图片，5万张是训练集，1万张做为验证/测试集。\n\n图片是28x28像素的，已经被打成长度为784的一维向量。\n我们可以随便选一张画出来看看：\nfrom matplotlib import pyplot as plt\nimport numpy as np\nplt.imshow(x_train[9].reshape((28,28)), cmap=&#039;gray&#039;)\n\nNumPy to Tensor\n因为是numpy array格式，我们需要转换成tensor。\nimport torch\n \nx_train, y_train, x_valid, y_valid = map(\n    torch.tensor, (x_train, y_train, x_valid, y_valid)\n)\nDataLoader\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\n \nbs = 64\n \ntrain_ds = TensorDataset(x_train, y_train)\ntrain_dl = DataLoader(train_ds, batch_size=bs)\n \nvalid_ds = TensorDataset(x_valid, y_valid)\nvalid_dl = DataLoader(valid_ds, batch_size=bs * 2)\n我们使用TensorDataSet来存这些数据，同时存samples和labels，再用DataLoader来方便我们访问和迭代这些数据，其中一个参数是batch_size，也就是批处理的大小，指定一次有多少个数据打包喂给神经网络。\n模型\n首先是看看有没有GPU，有则设备设为’cuda’，没有就设为’cpu’。我们的运算都在指定的device上进行。\ndevice = torch.device(&#039;cuda&#039; if torch.cuda.is_available() else &#039;cpu&#039;)\n训练步骤\n训练的代码都基本一样，我们把它写成一个函数，方便调用。\ndef train_step(model: torch.nn.Module,\n               data_loader,\n               loss_fn,\n               optimizer,\n               acc_fn,\n               device = device):\n \n    train_loss, train_acc = 0, 0\n    for batch, (X, y) in enumerate(data_loader):\n        X, y = X.to(device), y.to(device)\n        model.train()\n        y_pred = model(X)\n \n        loss = loss_fn(y_pred, y)\n        train_loss += loss\n        train_acc += acc_fn(y_pred, y)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n \n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n \n    print(f&quot;Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}&quot;)\n测试步骤\n测试步骤也是同样的道理，也写成函数：\ndef test_step(model,\n              data_loader,\n              loss_fn,\n              acc_fn,\n              device = device):\n \n    test_loss, test_acc=0, 0\n    model.eval()\n    with torch.inference_mode():\n        for X, y in data_loader:\n            X, y = X.to(device), y.to(device)\n            \n            test_pred = model(X)\n \n            test_loss += loss_fn(test_pred, y)\n            test_acc += acc_fn(test_pred.argmax(dim=1), y)\n            \n        test_loss /= len(data_loader)\n        test_acc /= len(data_loader)\n \n        print(f&quot;Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}\\n&quot;)\nCNN模型\n我们用poloclub.github.io/cnn-explainer/里的CNN架构，包含两个结构一样的blocks。\n\n这个架构是有名的VGG的简化版本，TinyVGG:\n\nfrom torch import nn\n \nclass MNIST(nn.Module):\n    def __init__(self, input_shape, hidden_units, output_shape):\n        super().__init__()\n        self.block_1 = nn.Sequential(\n            nn.Unflatten(1, (1, 28, 28)),\n            nn.Conv2d(\n                in_channels = input_shape,\n                out_channels = hidden_units,\n                kernel_size = 3,\n                stride=1,\n                padding=1),\n            nn.ReLU(),\n            nn.Conv2d(\n                hidden_units, hidden_units, 3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,\n                         stride=2)\n        )\n \n        self.block_2 = nn.Sequential(\n            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n \n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(in_features=hidden_units*7*7,\n                      out_features=output_shape)\n        )\n \n    def forward(self, x):\n        return self.classifier(self.block_2(self.block_1(x)))\n两个blocks都是Conv2d→ReLU→Conv2d→ReLU→MaxPool2d。参数前面都有解析过相应的概念了，这里需要讲的是在block_1里用了nn.Unflatten，是因为原来的数据28x28像素已经被转成一维向量了，所以此处需要搞回2维的数据。然后这里的卷积运算，用的kernel_size=3，stride=1，padding=1，这样子数据的形状大小是不变的；再通过MaxPool2d的时候，kernel_size=2, stride=2，所以一个2x2的数据就变成了1个数，数据就从28x28，变成了14x14。有两个blocks，过了两次MaxPooling，最终就变成了7x7，所以最后给nn.Linear的数据，就是7x7xhidden_units（也就是最后数据的通道数）。\n训练模型\n先初始化一个模型，input_shape就是传给卷积层的通道数，这里是灰度图，所以只有一个通道，hidden_units就是中间的通道数，而output_shape就是最后过全连接神经网络的输出，因为是0-9的数据，所以是10个分类。\ntorch.manual_seed(42)\n \nmodel = MNIST(input_shape=1, hidden_units=10, output_shape=10).to(device)\n\n还有相应的损失函数和优化器等：\nfrom torchmetrics.classification import Accuracy\nacc_fn = Accuracy(task=&quot;multiclass&quot;, num_classes=10).to(device)\n \nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(params=model.parameters(), \n                             lr=0.1)\n万事俱备，我们就可以开始训练了，有了前面训练步骤和测试步骤两个函数，就是把这些模型、损失函数、准确率函数和优化器给传进去就可以了。换一个模型和相应的这些函数，再传进去，就变成了训练另一个模型。\nfrom timeit import default_timer as timer \n \nstart_time = timer()\n \nepochs = 3\nfor epoch in range(epochs):\n    print(f&quot;Epoch: {epoch}\\n---&quot;)\n    \n    train_step(model=model, \n               data_loader=train_dl, \n               loss_fn=loss_fn, \n               optimizer=optimizer,\n               acc_fn=acc_fn)\n \n    test_step(model=model, \n              data_loader=valid_dl,\n              loss_fn=loss_fn,\n              acc_fn=acc_fn)\n \nend_time = timer()\n\n准确率达到了98%，6万张图片过了3遍，只用了17秒。\n评估\ny_preds = []\nmodel.eval()\nwith torch.inference_mode():\n  for X, y in valid_dl:\n    X, y = X.to(device), y.to(device)\n    y_logit = model(X)\n    y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n    y_preds.append(y_pred.cpu())\n    \ny_pred_tensor = torch.cat(y_preds)\n把验证数据集传给模型，把预测的结果拿到。我们就可以用前面定义的acc_fn来算一下准确率。\n\n和前面那个测试步骤最后的准确率是一样的，因为我们这里用的同一个数据集，也就是说这个数据集，既拿来测试，又拿来验证。一般情况下，我们可以把数据分成3个数据集，一个训练，一个验证，一个测试。因为这个下载的MNIST数据，本身就是分两块的，懒得再去切分它，就先这样用了。\n单纯一个准确率，是不清楚那些分类做得不好的，我们可以用混淆矩阵来看一下。\nfrom torchmetrics import ConfusionMatrix\nconfmat = ConfusionMatrix(num_classes=10, task=&#039;multiclass&#039;)\nconfmat_tensor = confmat(preds=y_pred_tensor, target=y_valid)\n这个代码就计算出了混淆矩阵，我们再画个图来看：\nfrom mlxtend.plotting import plot_confusion_matrix\n \nfig, ax = plot_confusion_matrix(\n    conf_mat = confmat_tensor.numpy(),\n    class_names = range(10)\n)\n"},"机器学习与统计方法/深度学习/基因组学深度学习入门指南":{"slug":"机器学习与统计方法/深度学习/基因组学深度学习入门指南","filePath":"机器学习与统计方法/深度学习/基因组学深度学习入门指南.md","title":"基因组学深度学习入门指南-转录因子结合位点识别","links":["[nature.com/articles/s41588-018-0295-5](https:/www.nature.com/articles/s41588-018-0295-5)"],"tags":["CNN","Pytorch","Genomics","DeepLearning","Classification"],"content":"这份教程是基于 Nature Genetics, 2018 的论文 “A Primer on Deep Learning in Genomics” 的补充材料编写的。我们将一步步看如何利用深度学习来解决基因组学中的一个经典问题：发现DNA中的转录因子结合位点。\n虽然原教程使用的是 Keras/TensorFlow，但为了适应现代深度学习的趋势，这里使用 PyTorch 框架进行重写和讲解。\n\n0. 背景知识\n什么是转录因子结合位点？\n在生物学中，转录因子（Transcription Factor, TF）是一种蛋白质，它们能够结合到DNA的特定区域，从而控制基因的表达（即基因是否被“开启”或“关闭”）。这些特定的DNA区域被称为转录因子结合位点（Binding Sites）。\n我们的任务\n我们希望训练一个神经网络模型，让它通过观察一段DNA序列，自动判断这段序列是否包含某个特定的转录因子结合位点。\n\n输入 (Input): 一段长度为 50 个碱基对 (bp) 的 DNA 序列（由 A, C, G, T 组成）。\n输出 (Output): 一个二分类标签（0 或 1）。\n\n1: 表示该序列与蛋白结合（包含结合位点）。\n0: 表示该序列不与蛋白结合（不含结合位点）。\n\n\n\n数据集\n为了方便学习，我们将使用一个模拟数据集。\n\n每个序列长度固定为 50。\n实际上，包含结合位点的序列里藏着一个特定的模式（Motif）：CGACCGAACTCC。\n我们的神经网络在训练前并不知道这个 Motif 是什么，它需要自己去“学习”并发现这个规律。\n\n\n1. 环境准备\n首先，我们需要导入必要的 Python 库。我们将使用 numpy 和 pandas 处理数据，使用 sklearn 进行数据预处理，使用 torch 构建和训练模型。\nimport numpy as np\nimport pandas as pd\nimport requests\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n \nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F\n \n# 设置随机种子，保证结果可复现\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n2. 数据准备与预处理 (Data Curation)\n2.1 加载数据\n数据托管在 GitHub 上，我们可以直接通过 URL 读取。\n# 定义数据 URL\nSEQUENCES_URL = &#039;raw.githubusercontent.com/abidlabs/deep-learning-genomics-primer/master/sequences.txt&#039;\nLABELS_URL = &#039;raw.githubusercontent.com/abidlabs/deep-learning-genomics-primer/master/labels.txt&#039;\n \n# 加载序列数据\nprint(&quot;正在下载序列数据...&quot;)\nsequences = requests.get(SEQUENCES_URL).text.split(&#039;\\n&#039;)\nsequences = list(filter(None, sequences))  # 移除可能的空行\n \n# 加载标签数据\nprint(&quot;正在下载标签数据...&quot;)\nlabels = requests.get(LABELS_URL).text.split(&#039;\\n&#039;)\nlabels = list(filter(None, labels))  # 移除可能的空行\n \n# 查看一下数据量\nprint(f&quot;总共有 {len(sequences)} 条序列，{len(labels)} 个标签。&quot;)\n \n# 查看第一条数据示例\nprint(f&quot;示例序列: {sequences[0]}&quot;)\nprint(f&quot;示例标签: {labels[0]}&quot;)\n \n# 正在下载序列数据... \n# 正在下载标签数据... \n# 总共有 2000 条序列，2000 个标签。 \n# 示例序列: CCGAGGGCTATGGTTTGGAAGTTAGAACCCTGGGGCTTCTCGCGGACACC \n# 示例标签: 0\n2.2 One-Hot 编码 (独热编码)\n神经网络无法直接理解 “ACGT” 这样的字符。我们需要将 DNA 序列转化为数字矩阵。最常用的方法是 One-Hot Encoding。\n对于 DNA 的 4 个碱基，我们可以这样表示：\n\nA: [1, 0, 0, 0]\nC: [0, 1, 0, 0]\nG: [0, 0, 1, 0]\nT: [0, 0, 0, 1]\n\n如果一段序列长度为 L (这里是 50)，那么它就会变成一个 L \\times 4 的矩阵。\n# 1. LabelEncoder: 将字符 (A, C, G, T) 转换为整数 (0, 1, 2, 3)\ninteger_encoder = LabelEncoder()\n# 2. OneHotEncoder: 将整数转换为 One-Hot 向量\none_hot_encoder = OneHotEncoder(categories=&#039;auto&#039;)\n \ninput_features = []\n \nprint(&quot;正在进行 One-Hot 编码...&quot;)\nfor sequence in sequences:\n    # 将字符串转为整数列表\n    integer_encoded = integer_encoder.fit_transform(list(sequence))\n    integer_encoded = np.array(integer_encoded).reshape(-1, 1)\n    \n    # 将整数转为 One-Hot 矩阵\n    one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n    input_features.append(one_hot_encoded.toarray())\n \n# 堆叠成一个大的 numpy 数组\n# 最终形状应该是 (样本数, 序列长度, 4)\ninput_features = np.stack(input_features)\n \nprint(f&quot;输入特征的形状: {input_features.shape}&quot;)\n \n# 正在进行 One-Hot 编码... \n# 输入特征的形状: (2000, 50, 4)\n同样地，我们也需要处理标签。虽然标签已经是 0 和 1，但为了规范，我们也可以将其转化为 numpy 数组。\nlabels = np.array(labels).astype(np.float32).reshape(-1, 1)\nprint(f&quot;标签形状: {labels.shape}&quot;)\n# 标签形状: (2000, 1)\n2.3 划分数据集\n我们将数据分为 训练集 (Training Set) 和 测试集 (Test Set)。训练集用于训练模型，测试集用于评估模型在未见过的数据上的表现。\n# 划分比例：75% 训练，25% 测试\nX_train, X_test, y_train, y_test = train_test_split(\n    input_features, labels, test_size=0.25, random_state=42\n)\n \nprint(f&quot;训练集大小: {X_train.shape}&quot;)\nprint(f&quot;测试集大小: {X_test.shape}&quot;)\n# 训练集大小: (1500, 50, 4) \n# 测试集大小: (500, 50, 4)\n2.4 转换为 PyTorch Tensor\nPyTorch 需要特定的数据格式：\n\n数据类型: 通常使用 float32。\n维度顺序: PyTorch 的一维卷积层 (Conv1d) 要求的输入形状是 (Batch_Size, Channels, Length)。\n\n我们要把 (N, 50, 4) 转换为 (N, 4, 50)。这很重要！\n\n\n\n\n# 转换为 Tensor 并调整维度 (Permute)\nX_train_t = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1)\nX_test_t = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n\ny_train_t = torch.tensor(y_train, dtype=torch.float32)\ny_test_t = torch.tensor(y_test, dtype=torch.float32)\n\n# 创建 DataLoader，用于批量加载数据\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\ntest_dataset = TensorDataset(X_test_t, y_test_t)\n\n# 批量大小 (Batch Size) 设为 32\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nprint(&quot;数据准备完成！&quot;)\n\n\n3. 构建模型 (Model Architecture)\n我们将构建一个简单的一维卷积神经网络 (1D CNN)。这在基因组学中非常常用，因为卷积核 (Kernel/Filter) 可以被看作是用来扫描 DNA 序列的“探针”，专门寻找特定的 Motif。\n模型结构设计\n\nConv1d 层:\n\nFilters (卷积核数量): 32。这意味着我们训练 32 个不同的“探针”来寻找特征。\nKernel Size (卷积核大小): 12。每个探针长度为 12 个碱基（对应我们要找的 Motif 长度约为 12）。\nInput Channels: 4 (对应 A, C, G, T)。\n\n\nReLU 激活函数: 引入非线性。\nMaxPool1d 层: 池化层。\n\nKernel Size: 4。对每 4 个位置取最大值，减少数据维度，保留最显著的特征。\n\n\nFlatten 层: 将多维特征展平为一维向量。\nLinear (全连接) 层 1: 隐藏层，16 个神经元。\nLinear (全连接) 层 2: 输出层，1 个神经元（输出属于正类的概率，配合 Sigmoid）。\n\n注意：原 Keras 代码使用的是 Softmax 输出 2 个值，PyTorch 中我们可以简化为输出 1 个值并使用 Sigmoid，或者输出 2 个值使用 CrossEntropy。这里我们采用输出 1 个值 + BCELoss (二元交叉熵损失) 的方式，这更符合二分类问题的直觉。\nclass GenomicsCNN(nn.Module):\n    def __init__(self):\n        super(GenomicsCNN, self).__init__()\n        \n        # 1. 一维卷积层\n        # in_channels=4 (A,C,G,T)\n        # out_channels=32 (我们要学习32种特征)\n        # kernel_size=12 (每次看12个碱基的窗口)\n        self.conv1 = nn.Conv1d(in_channels=4, out_channels=32, kernel_size=12)\n        \n        # 2. 最大池化层\n        self.pool = nn.MaxPool1d(kernel_size=4)\n        \n        # 3. 展平层\n        self.flatten = nn.Flatten()\n        \n        # 4. 计算 Flatten 后的维度\n        # 输入长度 L_in = 50\n        # Conv1d 后长度 L_out = L_in - kernel_size + 1 = 50 - 12 + 1 = 39\n        # MaxPool 后长度 L_out = floor(39 / 4) = 9\n        # 所以展平后的维度是 32 (channels) * 9 (length) = 288\n        self.flatten_dim = 32 * 9\n        \n        # 5. 全连接层\n        self.fc1 = nn.Linear(self.flatten_dim, 16)\n        self.fc2 = nn.Linear(16, 1) # 输出一个分数\n \n    def forward(self, x):\n        # x shape: [Batch, 4, 50]\n        \n        # 卷积 + ReLU\n        x = self.conv1(x)       # -&gt; [Batch, 32, 39]\n        x = F.relu(x)\n        \n        # 池化\n        x = self.pool(x)        # -&gt; [Batch, 32, 9]\n        \n        # 展平\n        # x = x.view(x.size(0), -1) # -&gt; [Batch, 288]\n        x = self.flatten(x)\n \n        # 全连接层 1\n        x = self.fc1(x)\n        x = F.relu(x)\n        \n        # 输出层 (这里不加 Sigmoid，因为我们在 Loss 函数中会用 BCEWithLogitsLoss，它包含了 Sigmoid，数值更稳定)\n        x = self.fc2(x)\n        \n        return x\n \n# 实例化模型\nmodel = GenomicsCNN()\nprint(model)\nGenomicsCNN( (conv1): Conv1d(4, 32, kernel_size=(12,), stride=(1,)) (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False) (flatten): Flatten(start_dim=1, end_dim=-1) (fc1): Linear(in_features=288, out_features=16, bias=True) (fc2): Linear(in_features=16, out_features=1, bias=True) )\n\n\n4. 训练模型 (Training)\n4.1 定义损失函数和优化器\n\nLoss Function: BCEWithLogitsLoss。这是处理二分类问题的标准损失函数，它结合了 Sigmoid 激活和 Binary Cross Entropy 损失。\nOptimizer: Adam。一种自适应学习率的优化算法，收敛速度快。\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n4.2 训练循环\n我们将遍历数据集多次（Epochs），每次通过前向传播计算预测值，计算损失，然后通过反向传播更新模型参数。\nepochs = 50\ntrain_losses = []\n \nprint(&quot;开始训练...&quot;)\nfor epoch in range(epochs):\n    model.train() # 设置为训练模式\n    running_loss = 0.0\n    \n    for inputs, labels in train_loader:\n        # 1. 清空梯度\n        optimizer.zero_grad()\n        \n        # 2. 前向传播\n        outputs = model(inputs)\n        \n        # 3. 计算损失\n        loss = criterion(outputs, labels)\n        \n        # 4. 反向传播与参数更新\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    \n    # 计算平均损失\n    avg_loss = running_loss / len(train_loader)\n    train_losses.append(avg_loss)\n    \n    if (epoch + 1) % 5 == 0:\n        print(f&quot;Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}&quot;)\n开始训练...\nEpoch [5/50], Loss: 0.1314\nEpoch [10/50], Loss: 0.0297\nEpoch [15/50], Loss: 0.0097\nEpoch [20/50], Loss: 0.0043\nEpoch [25/50], Loss: 0.0023\nEpoch [30/50], Loss: 0.0014\nEpoch [35/50], Loss: 0.0009\nEpoch [40/50], Loss: 0.0007\nEpoch [45/50], Loss: 0.0005\nEpoch [50/50], Loss: 0.0004\n# 绘制损失曲线\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label=&#039;Training Loss&#039;)\nplt.title(&#039;Training Loss over Epochs&#039;)\nplt.xlabel(&#039;Epoch&#039;)\nplt.ylabel(&#039;Loss&#039;)\nplt.legend()\nplt.show()\n\n5. 模型评估 (Evaluation)\n训练完成后，我们需要在测试集上评估模型的性能。\nmodel.eval() # 设置为评估模式\nall_preds = []\nall_labels = []\n \nprint(&quot;正在评估...&quot;)\nwith torch.no_grad(): # 不计算梯度，节省内存\n    for inputs, labels in test_loader:\n        outputs = model(inputs)\n        # 将输出 logits 转换为概率 (Sigmoid)\n        probs = torch.sigmoid(outputs)\n        # 将概率转换为 0 或 1 的预测 (阈值 0.5)\n        preds = (probs &gt; 0.5).float()\n        \n        all_preds.extend(preds.numpy())\n        all_labels.extend(labels.numpy())\n \n# 计算准确率\naccuracy = accuracy_score(all_labels, all_preds)\nprint(f&quot;测试集准确率 (Accuracy): {accuracy:.4f}&quot;)\n \n# 混淆矩阵\ncm = confusion_matrix(all_labels, all_preds)\nprint(&quot;混淆矩阵 (Confusion Matrix):&quot;)\nprint(cm)\n \n# 正在评估...\n# 测试集准确率 (Accuracy): 1.0000\n# 混淆矩阵 (Confusion Matrix):\n# [[259   0]\n#  [  0 241]]\n准确率是 1.0 (100%)，说明我们的模型非常完美地学会了识别那个隐藏的 Motif！\n\n6. 总结与下一步\n至此，我们已经成功构建并训练了一个基于 PyTorch 的深度学习模型，用于识别 DNA 序列中的功能性位点。\n主要步骤回顾：\n\n数据处理: 将 ACGT 序列转换为 One-Hot 矩阵。\n维度调整: 确保输入符合 PyTorch Conv1d 的 (N, C, L) 格式。\n模型构建: 使用 Conv1d 提取局部特征 (Motifs)。\n训练: 使用二元交叉熵损失函数进行优化。\n\n进阶思考：\n\n可解释性 (Interpretation): 我们如何知道模型到底学到了什么？我们可以通过分析第一层卷积核的权重，看看它们最喜欢激活什么样的 DNA 序列，从而反推出模型学到的 Motif 是否就是真实的 CGACCGAACTCC。这是计算生物学中非常重要的一步（通常称为 Motif Discovery）。\n\n7. 可解释性：打开黑盒子 (Interpretation)\n神经网络通常被认为是“黑盒子”，但对于 CNN，我们可以通过可视化卷积核的权重来理解它学到了什么。\n我们的模型第一层有 32 个卷积核（Filters），每个大小为 12。这 32 个卷积核就像 32 个“探针”，每个探针都在寻找一种特定的 DNA 序列模式（Motif）。\n如果一个 Filter 的权重在某个位置对 “A” 的值特别高，说明它很希望在该位置看到 “A”。\n我们可以编写一个简单的脚本 interpret_pytorch.py 来可视化这些权重：\nimport matplotlib.pyplot as plt\n \ndef plot_filters(model):\n    # 1. 获取第一层卷积层的权重\n    # shape: [32, 4, 12] -&gt; [Filters, Channels, Length]\n    weights = model.conv1.weight.detach().cpu().numpy()\n    \n    # 我们只选前 4 个 Filter 来展示\n    fig, axes = plt.subplots(4, 1, figsize=(10, 8))\n    \n    for i in range(4):\n        # 获取第 i 个 Filter 的权重\n        w = weights[i]\n        \n        # 绘制热图 (Heatmap)\n        ax = axes[i]\n        # cmap=&#039;viridis&#039; 是一种常用的颜色映射，黄色代表高数值，紫色代表低数值\n        ax.imshow(w, cmap=&#039;viridis&#039;, aspect=&#039;auto&#039;)\n        \n        ax.set_yticks([0, 1, 2, 3])\n        ax.set_yticklabels([&#039;A&#039;, &#039;C&#039;, &#039;G&#039;, &#039;T&#039;])\n        ax.set_title(f&#039;Filter {i+1} Weights&#039;)\n        \n    plt.tight_layout()\n    plt.show()\n \n# 在训练结束后调用\nplot_filters(model)\n\n如何解读图表？\n\n横轴: 卷积核的位置 (0 到 11)。\n纵轴: 4 种碱基 (A, C, G, T)。\n颜色: 颜色越亮（数值越大），说明该 Filter 在该位置越倾向于匹配该碱基。\nMotif 发现: 我们把颜色最亮的色块连起来，那么就成功“发现”了隐藏在数据中的 Motif！\n\n8. 进阶可视化：Sequence Logo (序列图标)\n虽然热图很有用，但我们更喜欢看 Sequence Logo。在 Sequence Logo 中，字母的高度代表了该位置上该碱基的重要性。\n我们可以通过对权重进行简单的数学转换（归一化为概率），然后使用 Matplotlib 绘制“变形”的字符来实现。\nfrom matplotlib.text import Text\nfrom matplotlib.patches import PathPatch\nfrom matplotlib.textpath import TextPath\nfrom matplotlib.font_manager import FontProperties\n \ndef draw_logo(all_scores, ax=None):\n    &quot;&quot;&quot;\n    绘制 Sequence Logo。\n    all_scores: shape [Length, 4], 每一行是 A, C, G, T 的分数(高度)\n    &quot;&quot;&quot;\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 3))\n    \n    # 定义碱基颜色\n    colors = {&#039;A&#039;: &#039;green&#039;, &#039;C&#039;: &#039;blue&#039;, &#039;G&#039;: &#039;orange&#039;, &#039;T&#039;: &#039;red&#039;}\n    bases = [&#039;A&#039;, &#039;C&#039;, &#039;G&#039;, &#039;T&#039;]\n    \n    x_len = all_scores.shape[0]\n    \n    # 遍历每一个位置\n    for i in range(x_len):\n        scores = all_scores[i] # 当前位置的 [score_A, score_C, score_G, score_T]\n        \n        # 将分数和碱基打包，并按分数从小到大排序\n        # 排序是为了让高的字母画在上面，或者按照某种堆叠逻辑\n        # 这里我们简单地从下往上堆叠\n        sorted_indices = np.argsort(scores)\n        \n        y_offset = 0\n        for idx in sorted_indices:\n            base = bases[idx]\n            score = scores[idx]\n            \n            if score &gt; 0:\n                # 核心黑科技：使用 TextPath 创建字母的路径，然后拉伸它\n                # 这里的代码参考了 logomaker 的底层实现原理\n                \n                # 1. 创建字体路径\n                txt = TextPath((0, 0), base, size=1, prop=FontProperties(family=&#039;sans-serif&#039;, weight=&#039;bold&#039;))\n                \n                # 2. 获取包围盒 (Bounding Box)\n                # 这是一个复杂的操作，为了简化，我们假设字母是标准化的\n                # 直接用 Transform 缩放\n                \n                # 更加简单的方法：使用 ax.text 并配合 transform\n                # 但 ax.text 不能非等比缩放 (拉长)。\n                # 所以我们必须用 PathPatch。\n                \n                # 重新计算变换\n                # 原理：TextPath 默认高度约为 1 (当 size=1)\n                # 我们需要将其缩放到高度 = score\n                # 宽度保持为 1\n                \n                vertices = txt.vertices\n                codes = txt.codes\n                \n                # 重新归一化字母的形状 (使其底边在 y=0, 高度为 1)\n                # 这步微调是为了让不同字母对齐\n                min_y = vertices[:, 1].min()\n                max_y = vertices[:, 1].max()\n                height_raw = max_y - min_y\n                \n                # 平移和缩放\n                new_vertices = vertices.copy()\n                new_vertices[:, 1] = (new_vertices[:, 1] - min_y) / height_raw * score + y_offset # 拉伸高度并平移\n                new_vertices[:, 0] = new_vertices[:, 0] + i # 平移到第 i 个位置\n                \n                patch = PathPatch(plt.matplotlib.path.Path(new_vertices, codes), facecolor=colors[base], edgecolor=&#039;none&#039;)\n                ax.add_patch(patch)\n                \n                y_offset += score\n \n    ax.set_xlim(-0.5, x_len + 0.5)\n    ax.set_ylim(0, np.max(all_scores.sum(axis=1)) * 1.1)\n    ax.set_xticks(range(x_len))\n    ax.set_xticklabels(range(1, x_len + 1)) # 改为从 1 开始计数，更符合生物学习惯\n    ax.set_xlabel(&#039;Position&#039;)\n    ax.set_ylabel(&#039;Importance / Probability&#039;)\n \ndef plot_motif_logos(model):\n    # 1. 获取权重 [32, 4, 12]\n    weights = model.conv1.weight.detach().cpu().numpy()\n    \n    # 2. 选择几个显著的 Filter\n    # 简单的启发式：选择权重方差最大的 Filter，这意味着它对某些碱基有强烈的偏好\n    variances = weights.var(axis=(1, 2))\n    top_indices = np.argsort(variances)[-4:][::-1] # 取方差最大的前4个\n    \n    fig, axes = plt.subplots(4, 1, figsize=(12, 10))\n    \n    for i, idx in enumerate(top_indices):\n        w = weights[idx] # [4, 12]\n        \n        # 3. 转换为 PPM (Position Probability Matrix) 近似值\n        # 方法：先 ReLU (把负值去掉)，因为我们只关心正向激活\n        # 然后归一化\n        w = np.maximum(w, 0) \n        \n        # 避免除以 0\n        row_sums = w.sum(axis=0, keepdims=True)\n        row_sums[row_sums == 0] = 1\n        ppm = w / row_sums \n        \n        # 这里的 ppm shape 是 [4, 12]，我们要转置成 [12, 4] 给绘图函数\n        ppm = ppm.T\n        \n        # 如果你想加入 Information Content 的概念：\n        # IC = ppm * (2 - entropy) ... 这里为了简单，直接画 PPM\n        \n        draw_logo(ppm, ax=axes[i])\n        axes[i].set_title(f&#039;Filter {idx} Sequence Logo&#039;)\n        \n    plt.tight_layout()\n    plt.show()\n \nplot_motif_logos(model)\n\n这个代码会：\n\n自动挑选出最“显著”的 4 个卷积核（方差最大的）。\n画出 4 张 Sequence Logo 图。\n\n9. 进阶：探索模型的注意力 (Saliency Maps)\n虽然看权重（Weights）是最直接的方法，但在更复杂的场景下，我们通常会使用 Saliency Maps（显著性图）。\n这些方法不是看“模型脑子里存了什么模板”，而是看“对于当前的输入，哪个碱基对预测结果贡献最大”。\n这利用了梯度的概念：如果我们稍微改变输入序列中第 i 个位置的碱基，模型的预测分数会发生剧烈变化吗？如果会，说明第 i 个位置非常重要（梯度大）。\n梯度就是“敏感度”，这就是Saliency Maps的实现原理。这是反向传播的一个妙用：\n\n\n通常我们训练时，是求Loss对权重的梯度，以此来更新权重。\n\n\n但在Saliency Maps中，我们固定权重，求Score（预测值）对输入的梯度。\n\n\nprint(&quot;加载数据...&quot;)\n \n# 我们只需要加载一条正样本 (Label=1)\nSEQUENCES_URL = &#039;raw.githubusercontent.com/abidlabs/deep-learning-genomics-primer/master/sequences.txt&#039;\nLABELS_URL = &#039;raw.githubusercontent.com/abidlabs/deep-learning-genomics-primer/master/labels.txt&#039;\n \n# 简单粗暴：下载并找到第一个 Label 为 1 的序列\nsequences = list(filter(None, requests.get(SEQUENCES_URL).text.split(&#039;\\n&#039;)))\nlabels = list(filter(None, requests.get(LABELS_URL).text.split(&#039;\\n&#039;)))\n \n# 找到第一个正样本的索引\ntarget_idx = -1\nfor i, label in enumerate(labels):\n    if label == &#039;1&#039;:\n        target_idx = i\n        break\n \nif target_idx == -1:\n    print(&quot;未找到正样本！&quot;)\n    exit()\n \ntarget_seq = sequences[target_idx]\nprint(f&quot;分析序列 #{target_idx}: {target_seq}&quot;)\n \n# 预处理：One-Hot 编码\ninteger_encoder = LabelEncoder()\none_hot_encoder = OneHotEncoder(categories=&#039;auto&#039;)\ninteger_encoded = integer_encoder.fit_transform(list(target_seq))\ninteger_encoded = np.array(integer_encoded).reshape(-1, 1)\none_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\ninput_feature = one_hot_encoded.toarray() # shape [50, 4]\n \n# 转为 Tensor: [1, 4, 50]\ninput_tensor = torch.tensor(input_feature, dtype=torch.float32).permute(1, 0).unsqueeze(0)\n \n \n# ==========================================\n# Saliency Map 计算 (核心逻辑)\n# ==========================================\n \nprint(&quot;计算 Saliency Map...&quot;)\n \n# 关键步骤 1: 启用输入梯度\ninput_tensor.requires_grad_()\n \n# 关键步骤 2: 前向传播\noutput = model(input_tensor)\n \n# 关键步骤 3: 反向传播\n# 我们希望解释&quot;为什么预测结果是正类&quot;，所以直接对 output 求导\noutput.backward()\n \n# 关键步骤 4: 获取梯度并处理\n# 梯度形状: [1, 4, 50] -&gt; 取绝对值 -&gt; 在通道维度求和 -&gt; [50]\ngradients = input_tensor.grad.data.abs().squeeze().numpy()\nsaliency = gradients.sum(axis=0)\n \n \n# ==========================================\n# 4. 可视化\n# ==========================================\n \nfig, ax = plt.subplots(figsize=(15, 5))\nax.bar(range(50), saliency, color=&#039;purple&#039;, alpha=0.7)\nax.set_title(f&#039;Saliency Map for Sequence #{target_idx} (Label=1)&#039;)\nax.set_xlabel(&#039;Position&#039;)\nax.set_ylabel(&#039;Gradient Magnitude (Importance)&#039;)\nax.set_xlim(-0.5, 49.5)\n \n# 在 X 轴下方标记碱基\nax.set_xticks(range(50))\nax.set_xticklabels(list(target_seq), fontsize=9, fontfamily=&#039;monospace&#039;)\n \nplt.tight_layout()\nplt.show()\n\n这张柱状图，展示了 DNA 序列的每一个位置对模型决策的“贡献度”。通常，真正的结合位点（Motif）所在的位置，其梯度值会远远高于背景噪声。"},"机器学习与统计方法/深度学习/用PyTorch训练简单线性回归":{"slug":"机器学习与统计方法/深度学习/用PyTorch训练简单线性回归","filePath":"机器学习与统计方法/深度学习/用PyTorch训练简单线性回归.md","title":"用PyTorch训练简单线性回归","links":[],"tags":["DeepLearning","Pytorch","Regression"],"content":"上次手搓一个简单的线性回归，这次该上PyTorch了。\nimport torch  \nfrom torch import nn\n数据\n还用上一次的数据：\n\n先转成Tensor:\nX = torch.tensor(df[&#039;population&#039;].values, dtype=torch.float)  \ny = torch.tensor(df[&#039;profit&#039;].values, dtype=torch.float)  \nX = X.view(len(X), 1)  \ny = y.view(len(y), 1)\n定义模型\nclass LinearRegressionModel(nn.Module):  \n    def __init__(self):  \n        super().__init__()  \n        self.linear_layer = nn.Linear(in_features=1, out_features=1)  \n      \n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:  \n        return self.linear_layer(x)\n然后我们需要初始化一个模型对象，指定用什么loss function和optimizer：\nmodel = LinearRegressionModel()  \n  \nloss_fn = nn.L1Loss()  \n  \noptimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)\n训练\n无非是搭积木：\nepochs = 5000  \n  \nfor epoch in range(epochs):  \n    model.train()  \n      \n    y_pred = model(X)  \n    loss = loss_fn(y_pred, y)  \n      \n    optimizer.zero_grad()  \n    loss.backward()  \n    optimizer.step()\n结果\n"},"机器学习与统计方法/深度学习/神经网络对数据进行二分类":{"slug":"机器学习与统计方法/深度学习/神经网络对数据进行二分类","filePath":"机器学习与统计方法/深度学习/神经网络对数据进行二分类.md","title":"神经网络对数据进行二分类","links":[],"tags":["DeepLearning","Classification","Pytorch"],"content":"\n没有GPU，无法AI :)\n数据\n这个数据是随机生成的，用的sklearn里的make_moons\nRANDOM_SEED = 42\n \nfrom sklearn.datasets import make_moons\n \nn_samples = 1000\n \nX, y = make_moons(n_samples = n_samples, noise = 0.2, random_state=RANDOM_SEED)\n画个图看一眼：\nimport pandas as pd\n \nX_df = pd.DataFrame(X)\n \nimport matplotlib.pyplot as plt\n \nplt.scatter(X_df[0], X_df[1], c=y)\n\n因为我们训练是在GPU上，所以数据我们需要也放到GPU上，再者数据要拆分为训练集和测试集，这里依然使用sklearn中的函数，train_test_split，80%的数据用于训练，20%的数据用于测试。\nX = torch.tensor(X, dtype=torch.float).to(device)\ny = torch.tensor(y, dtype=torch.float).to(device)\n \nfrom sklearn.model_selection import train_test_split\n \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n模型\n继续我们的PyTorch学习，上一次在《用PyTorch训练简单线性回归》中我们定义了继承nn.Module的类。对于简单的神经网络来说，我们用nn.Sequential就可以了，连forward函数都省了。\nimport torch\nfrom torch import nn\n \nBinaryClassification = nn.Sequential(\n    nn.Linear(in_features = 2, out_features = 10),\n    nn.ReLU(),\n    nn.Linear(in_features = 10, out_features = 10),\n    nn.ReLU(),\n    nn.Linear(in_features = 10, out_features = 1)\n).to(device)\n\n这里用的数据是个二维的数据，当然多少维都一样，就是in_features数改一下而已，这里二维，进来就接10个神经元，我们也可以认为是对数据进行了升维，然后再接10个神经元，最后的输出就是所谓的logit，所以分类叫logistic regression嘛。把这个logit值再过一个sigmoid函数，就是分类的概率了。这里每一层线性回归，都要加一个激活函数，这里用了ReLU，但也可以是别的。这就是我在《简单线性回归》最后写的：\n\n损失函数\nloss_fn = nn.BCEWithLogitsLoss()\n这里是分类，分类的损失函数可以用交叉熵（Cross Entropy），这里是二分类就有相应的Binary Cross Entropy，所谓损失函数，就是比较真实label和预测的label的差距，优化的过程就是希望这个差距越来越小。我们的模型输出的是logits，需要过一个sigmoid，才能预测label，然后才能使用交叉熵来计算损失，所以是两步。那么这里使用的nn.BCEWithLogitsLoss()就是整合了这两步，而且会比自己拆分两步来计算在数值上会更稳健一些。\n优化器\noptimizer = torch.optim.SGD(params = BinaryClassification.parameters(), lr = 0.1)\n这里用了torch.optim.SGD也就是随机梯度下降，这是很常见的优化器，这里设置学习率为0.1。\n准确率\n我们需要定义一个函数，来度量一下模型的准确率，这个函数很简单，就是预测的label和真实的label是否相等的平均值（相等的个数/总数）。虽然函数很简单，但我们不需要自己定义，可以用torchmetrics，用这个模块还能方便我们在需要的时候用更多的指标。\nfrom torchmetrics.classification import Accuracy\n \nacc_fn = Accuracy(task=&quot;multiclass&quot;, num_classes=2).to(device)\n训练模型\nfrom timeit import default_timer as timer \n \nstart_time = timer()\n \nepochs = 1000\n \nfor epoch in range(epochs):\n    ## Training\n    BinaryClassification.train()\n \n    y_logits = BinaryClassification(X_train).squeeze()\n    y_pred = torch.round(torch.sigmoid(y_logits))\n \n    loss = loss_fn(y_logits, y_train)\n    acc = acc_fn(y_pred, y_train)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n \n    ## Testing\n    BinaryClassification.eval()\n    with torch.inference_mode():\n        test_logits = BinaryClassification(X_test).squeeze()\n        test_pred = torch.round(torch.sigmoid(test_logits))\n        test_loss = loss_fn(test_logits, y_test)\n        test_acc = acc_fn(test_pred, y_test)\n \n    if epoch % 100 == 0:\n        print(f&quot;Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%&quot;)\n \nend_time = timer()\n这里使用了timeit来记录时间，epochs用了1000，其实不用这么多，很快就收敛了。每个epoch里分两段，一段是训练，就是数据进去，计算损失，优化参数。另一段是是用测试集进行测试，这里用了torch.inference_mode()，因为测试的时候，没有优化过程，也就不需要去跟踪参数，会更快更省内存，测试阶段就只需要把数据扔进模型，计算一个损失和准确率。\n最后是每100个epochs，打印一下相应的信息，让我们了解模型训练的表现。\n\n到了100个epochs的时候，准确率在训练集和测试集上都已经&gt;80%了\n\n所用的时间，不到3秒。\n可视化\n最后我们可以画一下，模型在训练集和测试集中的分类情况：\n"},"机器学习与统计方法/深度学习/简单线性回归":{"slug":"机器学习与统计方法/深度学习/简单线性回归","filePath":"机器学习与统计方法/深度学习/简单线性回归.md","title":"简单线性回归","links":[],"tags":["DeepLearning","Regression"],"content":"上一次说AI学起来，这就学起来。\n先来个简单的线性回归。\n假如要开一家餐馆，街区人口和利润是关联，从已经开的店的数据，预测一下，预测在新的街区开店的收入是多少。\n读入数据\nimport pandas as pd  \ndf = pd.read_csv(&quot;data/street-profits.csv&quot;, names=[&#039;population&#039;, &#039;profit&#039;])\ndf.head()  \n  \npopulation profit  \n0 6.1101 17.5920  \n1 5.5277 9.1302  \n2 8.5186 13.6620  \n3 7.0032 11.8540  \n4 5.8598 6.8233\n线性回归\ny = theta_0 + theta_1 * x，把 x加一个column是1，这样子就可以变成y = theta @ X.\nimport numpy as np  \ndf[&#039;b&#039;] = np.ones(df.shape[0])  \nX = df[[&#039;population&#039;, &#039;b&#039;]]  \ntheta = np.zeros(X.shape[1])  \ny = df.profit\n用均方误差（MSE）来定义cost function。\ndef mse(theta, X, y):  \n    # MSE: Mean Squared Error  \n    m = X.size  \n    inner = X @ theta - y  \n    square_sum = inner.T @ inner  \n    cost = square_sum / (2*m)  \n    return cost\n线性回归变成一个优化的问题，就是让代价函数最小。进行偏微分，就可以得到参数更新的方向和大小。alpha是所谓的learning rate。\n:= \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} \\bigl( h_\\theta(x^{(i)}) - y^{(i)} \\bigr) x_j^{(i)}$$\n这个公式其实是我们大一都学过的泰勒公式。  \n\n![](assets/简单线性回归/file-20251219233631986.png)\n\n在x接近a的时候，(x-a)就很少，后面多次方的项就可以忽略，这就成为了上面的公式了，而这个(x-a)就是alpha，就是在这里被称为learning rate的这一项，也就是说这个公式本身要成立，前提就是alpha很小。  \n\n下面的`gradient`函数算的就是偏微分的这块：\n\n```python\ndef gradient(theta, X, y):  \n    m = X.size  \n    inner = X.T @ (X @ theta - y)  \n    return inner/m\n```\n### 批量梯度下降算法\n\n按照上面的公式来计算。\n\n```python\ndef batch_gradient_descent(theta, X, y, epoch, alpha=0.01):  \n    cost_data = [mse(theta, X, y)]  \n    _theta = theta.copy()  \n  \n    for _ in range(epoch):  \n        _theta = _theta - alpha * gradient(_theta, X, y)  \n        cost_data.append(mse(_theta, X, y))  \n    return _theta, cost_data\n```\n\n搞个5000次迭代，出来最后的参数：\n```python\nepoch = 5000  \nfinal_theta, cost_data = batch_gradient_descent(theta, X, y, epoch)\n```\n\n\n\n## scikit-learn\n\n比较一下，才知道行不行。\n\n```python\nfrom sklearn import linear_model   model = linear_model.LinearRegression()   model.fit(X, y)`\n```\n\n![Image](mmbiz.qpic.cn/mmbiz_png/MPBFtnFrw4kcgwEwBWf2ibGdkNBMW5waHlAfnfOqLhWgLSibCK0IWJicnD2Sxc6bEcDZeoc9UuQCmf5z611icV79oA/640#imgIndex=1)\n\n学会了线性回归，就离神经网络不远了😄\n\n\n因为每个神经元都是一个线性回归，再加一个激活函数。神经网络就是一堆神经元，而再多的线性回归组合在一起，它还是一个线性函数，以二维来说，就还是一条直线，那有没有办法拟合任意曲线，那就需要带拐弯的，这就是激活函数要干的事，简单如ReLU，就是带个拐，就可以了。有拐弯，只要够多，经过缩放、位移、组合，就可以各种拐，而只要点足够多，直线拐也能平滑地拟和曲线，所以它就能拟合所有曲线，推广到高维空间，也是一样。"},"机器学习与统计方法/简单的KMeans":{"slug":"机器学习与统计方法/简单的KMeans","filePath":"机器学习与统计方法/简单的KMeans.md","title":"简单的KMeans","links":[],"tags":["MachineLearning","Classification","KMeans"],"content":"KMeans算法有两个假设：\n\n\n“簇中心点”是属于该簇的所有数据点坐标的算术平均值。\n\n\n一个簇的每个点到该簇中心点的距离，比到其他簇中心点的距离短。\n\n\nsklearn实例\n数据\nfrom sklearn.datasets import make_blobs\n \nX, y = make_blobs(n_samples = 300, centers = 4, cluster_std=0.5, random_state=0)\n用sklearn生成一个示例数据。我们画个图看看：\nimport matplotlib.pyplot as plt\n \nplt.scatter(X[:, 0], X[:, 1], s=50)\n\n很清楚，就是4个类。然后我们用kmeans算法来聚类。\nKMeans聚类\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=4)\nkmeans.fit(X)\n \ny_pred = kmeans.predict(X)\nsklearn的套路：1. 初始化模型（包括指定一些超参数），2. 拟合数据（或者叫训练），3. 预测。打完收工，我们画个图看看：\nplt.scatter(X[:, 0], X[:, 1], s=50, c=y_pred, cmap=&#039;viridis&#039;)\n\n我们也可以把中心点画在上面：\nplt.scatter(X[:, 0], X[:, 1], s=50, c=y_pred, cmap=&#039;viridis&#039;)\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c=&#039;red&#039;, s=200, alpha=0.8)\n\n自己写个KMeans的乐趣\n自己写的一个好处是你可以记录一下迭代过程中的中心点位置，然后拿来画图，对于KMeans的过程会有直观的感受，你也会发现收敛得很快。这就是我在2011年的时候用R写的代码出的图：\n\n此处还有一段用Python写的KMeans可供参考。\nKMeans还能干点啥？\n它能做图片压缩，对颜色进行聚类，然后用中心点去替换相似的颜色，比如说一张图，你给压缩成16色的，图片就可以小很多。这也是当年写了KMeans之后，干过的一件事情。然后还可以有一个类似的事情可以干，我把图片颜色的中心点拿出来，这不等到把配色方案拿到手了么？然后你就可以将其应用于自己的图中。也就是说你上班摸鱼在看图，就有借口说自己在找配色方案了。这就是当年写下这篇《食色性也》所介绍的。\n\nKMeans不能干啥\n从前面说到的KMeans的两个假设，就可以看出来，不符合这两个假设，它就不能干啊。因为KMeans只能确定线性聚类边界，所以当边界很复杂的时候，它是做不好的。比如我在《AI学起来，毕竟AI让地球运转》里放的这张用SVM分类的图，用KMeans就做不好。\n\n但是我们想一想，SVM是怎么做的？应用一个核函数，将数据投影到更高维的空间，然后是线性可分的，在高维空间进行分类。既然在高维空间是线性可分的，那么用KMeans也是可以的。所以像这种KMeans干不来的分类，如果我们组合一个核变换+KMeans，那么它也是干得来的。\n欲知后事如何，请听下回分解。"}}